{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c988869a",
   "metadata": {},
   "source": [
    "# Uncovering Healthcare Inefficiencies - Model Building and Evaluation\n",
    "\n",
    "This notebook focuses on building, training, and evaluating various models to determine the best performing model for our dataset.\n",
    "\n",
    "The models included in this notebook are:\n",
    "\n",
    "1. **Logistic Regression**: Used as the baseline model.\n",
    "2. **Ridge Classifier**: Classification model using L2 regularization.\n",
    "3. **Lasso Classifier**: Classification model using L1 regularization.\n",
    "4. **XGBoost**: Powerful gradient boosting framework.\n",
    "5. **Agglomerative Clustering**: Hierarchical clustering method.\n",
    "6. **DBSCAN**: Unsupervised clustering to identify clusters and noise.\n",
    "7. **Kmeans**: Another unsupervised clustering to identify clusters and noise.\n",
    "\n",
    "Each model undergoes the following steps:\n",
    "\n",
    "1. **Data Preprocessing**: Standardizing and preparing data.\n",
    "2. **Model Building**: Constructing model architecture.\n",
    "3. **Model Training**: Training the model.\n",
    "4. **Model Evaluation**: Assessing performance.\n",
    "5. **Results Analysis**: Comparing results to determine the best model.\n",
    "\n",
    "\n",
    "The objective is to identify the model that yields the best results in terms of accuracy and other relevant metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832db883-2ab1-42e5-ae63-18a0d0753abb",
   "metadata": {},
   "source": [
    "## Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f34cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV,  KFold, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, silhouette_score\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # supress warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3cd24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/amyou/Desktop/ADS 599 Capstone/healthcare-market-saturation-fraud\n"
     ]
    }
   ],
   "source": [
    "# Check current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd07646",
   "metadata": {},
   "source": [
    "## Import data from preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf93427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "# all the training/validation/test dataframes\n",
    "x_train = pd.read_csv('data/x_train.csv') \n",
    "x_train_scaled = pd.read_csv('data/x_train_scaled.csv')\n",
    "x_train_pca = pd.read_csv('data/x_train_pca.csv')\n",
    "x_train_scaled_pca = pd.read_csv('data/x_train_scaled_pca.csv')\n",
    "\n",
    "x_val = pd.read_csv('data/x_val.csv') \n",
    "x_val_scaled = pd.read_csv('data/x_val_scaled.csv')\n",
    "x_val_pca = pd.read_csv('data/x_val_pca.csv')\n",
    "x_val_scaled_pca = pd.read_csv('data/x_val_scaled_pca.csv')\n",
    "\n",
    "x_test = pd.read_csv('data/x_test.csv')\n",
    "x_test_scaled = pd.read_csv('data/x_test_scaled.csv')\n",
    "x_test_pca = pd.read_csv('data/x_test_pca.csv')\n",
    "x_test_scaled_pca = pd.read_csv('data/x_test_scaled_pca.csv')\n",
    "\n",
    "\n",
    "# all the labels\n",
    "y_train = np.ravel(pd.read_csv('data/y_train.csv'))\n",
    "y_val = np.ravel(pd.read_csv('data/y_val.csv'))\n",
    "y_test = np.ravel(pd.read_csv('data/y_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d9c92",
   "metadata": {},
   "source": [
    "## DataTransformation \n",
    "\n",
    "### Yeo Johnson transformation of data\n",
    "\n",
    "We wanted to add in additional dataframes to see if there was a difference in modeling performance. This Yeo-Johnson transformation was one of them, another would be to do transformation + scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd538566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "# transformed data\n",
    "# create copy of df \n",
    "x_train_transformed = x_train.copy()\n",
    "x_val_transformed = x_val.copy()\n",
    "x_test_transformed = x_test.copy()\n",
    "\n",
    "# get numeric columns\n",
    "numeric_columns = x_train_transformed.select_dtypes(include=['float']).columns\n",
    "\n",
    "def yeo_johnson_transform(column):\n",
    "    # Create an instance of PowerTransformer with Yeo-Johnson method\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    # Reshape column for PowerTransformer which expects 2D input\n",
    "    column_reshaped = column.values.reshape(-1, 1)\n",
    "    \n",
    "    # Fit and transform the column\n",
    "    transformed_col = pt.fit_transform(column_reshaped)\n",
    "    \n",
    "    # Flatten the result to match original column shape\n",
    "    return transformed_col.flatten()\n",
    "\n",
    "# Apply Box-Cox transformation to each numeric column\n",
    "for col in numeric_columns:\n",
    "    x_train_transformed[col] = yeo_johnson_transform(x_train_transformed[col])\n",
    "    x_val_transformed[col] = yeo_johnson_transform(x_val_transformed[col])\n",
    "    x_test_transformed[col] = yeo_johnson_transform(x_test_transformed[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e87ee19",
   "metadata": {},
   "source": [
    "### Log transformed + scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87097630",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trans_scaled = x_train_transformed.copy()\n",
    "x_val_trans_scaled = x_val_transformed.copy()\n",
    "x_test_trans_scaled = x_test_transformed.copy()\n",
    "\n",
    "scaler = RobustScaler()\n",
    "x_train_trans_scaled[numeric_columns] = scaler.fit_transform(x_train_trans_scaled[numeric_columns])\n",
    "x_val_trans_scaled[numeric_columns] = scaler.transform(x_val_trans_scaled[numeric_columns])\n",
    "x_test_trans_scaled[numeric_columns] = scaler.transform(x_test_trans_scaled[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced5f2b",
   "metadata": {},
   "source": [
    "## Baseline Model Selection - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461c82d",
   "metadata": {},
   "source": [
    "We'll first start by deciding on a baseline model for comparison against other models. The confusion matrix will be used to determine which dataframe will be ingested for each machine learning model. We currently have the following dataframes/data to feed into the logistic regression model:\n",
    "\n",
    "* The preprocessed data - x_train\n",
    "* The transformed data - x_train_tranformed\n",
    "* The scaled data - x_train_scaled\n",
    "* The transformed + scaled data - x_train_trans_scaled\n",
    "* The pca transformed data - x_train_pca\n",
    "* The scaled data + pca - x_train_scaled_pca\n",
    "\n",
    "Based on the results of the baseline regression model, we can choose a dataframe to carry through the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2985f35",
   "metadata": {},
   "source": [
    "### Create and train Logistic Regression Model for unscaled data\n",
    "\n",
    "This is the first model with the data that has been preprocessed but not scaled nor transformed for normality. The accuracy was terrible, the precision and F-score were non existant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a08832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.25420515406663136\n",
      "Validation Confusion Matrix:\n",
      "[[     0 116831]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    116831\n",
      "           1       0.25      1.00      0.41     39822\n",
      "\n",
      "    accuracy                           0.25    156653\n",
      "   macro avg       0.13      0.50      0.20    156653\n",
      "weighted avg       0.06      0.25      0.10    156653\n",
      "\n",
      "Test Accuracy: 0.25420353134934315\n",
      "Test Confusion Matrix:\n",
      "[[     0 116832]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    116832\n",
      "           1       0.25      1.00      0.41     39822\n",
      "\n",
      "    accuracy                           0.25    156654\n",
      "   macro avg       0.13      0.50      0.20    156654\n",
      "weighted avg       0.06      0.25      0.10    156654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747ae41",
   "metadata": {},
   "source": [
    "### Create and train Logistic Regression Model for the scaled data\n",
    "\n",
    "This is the first model with the data that has been preprocessed and scaled, but not transformed for normality. The accuracy was 100%, leading us to believe that the model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "257255a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amyou/opt/anaconda3/envs/Newenvironment/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n",
      "Validation Confusion Matrix:\n",
      "[[116831      0]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116831\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156653\n",
      "   macro avg       1.00      1.00      1.00    156653\n",
      "weighted avg       1.00      1.00      1.00    156653\n",
      "\n",
      "Test Accuracy: 1.0\n",
      "Test Confusion Matrix:\n",
      "[[116832      0]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116832\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156654\n",
      "   macro avg       1.00      1.00      1.00    156654\n",
      "weighted avg       1.00      1.00      1.00    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_scaled)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f2c69",
   "metadata": {},
   "source": [
    "### Create and train Logistic Regression Model for yeo-johnson transformed data\n",
    "\n",
    "This is the first model with the data that has been preprocessed and transformed, but not scaled. The accuracy was 100%, leading us to believe that the model is also overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8ef62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n",
      "Validation Confusion Matrix:\n",
      "[[116831      0]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116831\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156653\n",
      "   macro avg       1.00      1.00      1.00    156653\n",
      "weighted avg       1.00      1.00      1.00    156653\n",
      "\n",
      "Test Accuracy: 1.0\n",
      "Test Confusion Matrix:\n",
      "[[116832      0]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116832\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156654\n",
      "   macro avg       1.00      1.00      1.00    156654\n",
      "weighted avg       1.00      1.00      1.00    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_transformed, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_transformed)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_transformed)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce41b5",
   "metadata": {},
   "source": [
    "### Create and train Logistic Regression Model for yeo-johnson transformed and scaled data\n",
    "\n",
    "This is the first model with the data that has been preprocessed, scaled, and transformed for normality. The accuracy was 100%, leading us to believe that the model is also overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8b7521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n",
      "Validation Confusion Matrix:\n",
      "[[116831      0]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116831\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156653\n",
      "   macro avg       1.00      1.00      1.00    156653\n",
      "weighted avg       1.00      1.00      1.00    156653\n",
      "\n",
      "Test Accuracy: 1.0\n",
      "Test Confusion Matrix:\n",
      "[[116832      0]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116832\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156654\n",
      "   macro avg       1.00      1.00      1.00    156654\n",
      "weighted avg       1.00      1.00      1.00    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_trans_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_trans_scaled)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_trans_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52b7ac",
   "metadata": {},
   "source": [
    "### Create and train Logistic Regression Model for the PCA transformed data (orig)\n",
    "\n",
    "This is the fifth model with the data that has been preprocessed, but not scaled nor transformed for normality. The accuracy was about 81%, which is the best model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ebc563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8094706133939343\n",
      "Validation Confusion Matrix:\n",
      "[[114853   1978]\n",
      " [ 27869  11953]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.89    116831\n",
      "           1       0.86      0.30      0.44     39822\n",
      "\n",
      "    accuracy                           0.81    156653\n",
      "   macro avg       0.83      0.64      0.66    156653\n",
      "weighted avg       0.82      0.81      0.77    156653\n",
      "\n",
      "Test Accuracy: 0.8097080189462127\n",
      "Test Confusion Matrix:\n",
      "[[114859   1973]\n",
      " [ 27837  11985]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.89    116832\n",
      "           1       0.86      0.30      0.45     39822\n",
      "\n",
      "    accuracy                           0.81    156654\n",
      "   macro avg       0.83      0.64      0.67    156654\n",
      "weighted avg       0.82      0.81      0.77    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_pca, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_pca)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_pca)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0b7d7",
   "metadata": {},
   "source": [
    "### Create and train Logistic Regression Model for the PCA transformed data (scaled)\n",
    "\n",
    "This is the sixth model with the data that has been preprocessed and scaled, but not transformed for normality. The accuracy was about 82%, which is the best model so far beating the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0cfd633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8236739800706019\n",
      "Validation Confusion Matrix:\n",
      "[[107864   8967]\n",
      " [ 18655  21167]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89    116831\n",
      "           1       0.70      0.53      0.61     39822\n",
      "\n",
      "    accuracy                           0.82    156653\n",
      "   macro avg       0.78      0.73      0.75    156653\n",
      "weighted avg       0.81      0.82      0.81    156653\n",
      "\n",
      "Test Accuracy: 0.82516245994357\n",
      "Test Confusion Matrix:\n",
      "[[108066   8766]\n",
      " [ 18623  21199]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89    116832\n",
      "           1       0.71      0.53      0.61     39822\n",
      "\n",
      "    accuracy                           0.83    156654\n",
      "   macro avg       0.78      0.73      0.75    156654\n",
      "weighted avg       0.82      0.83      0.82    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_scaled_pca, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_scaled_pca)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_scaled_pca)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ab45a-27f0-4cad-ab0e-45d49b5988f3",
   "metadata": {},
   "source": [
    "We opted to use PCA-transformed and scaled data for creating and training our Logistic Regression model for several compelling reasons:\n",
    "\n",
    "1. **Dimensionality Reduction**:\n",
    "   - **Principal Component Analysis (PCA)** is a powerful technique used to reduce the dimensionality of our dataset while retaining the most important information. This helps in eliminating redundant and less informative features, leading to a more efficient and interpretable model.\n",
    "\n",
    "2. **Feature Scaling**:\n",
    "   - Scaling our data ensures that all features contribute equally to the model. Logistic Regression, like many machine learning algorithms, performs better when the data is normalized, preventing features with larger scales from dominating the model training process.\n",
    "\n",
    "3. **Model Performance**:\n",
    "   - The Logistic Regression model trained on PCA-transformed and scaled data achieved an accuracy of about 82%. This is a significant improvement over previous models and is currently our best-performing model. The use of PCA likely helped in capturing the underlying structure of the data more effectively.\n",
    "\n",
    "4. **Overfitting Reduction**:\n",
    "   - By reducing the number of features, PCA helps in minimizing the risk of overfitting. Overfitting occurs when the model is too complex and captures noise in the data, rather than the actual underlying pattern. PCA helps in addressing this by simplifying the feature set.\n",
    "\n",
    "5. **Computational Efficiency**:\n",
    "   - With fewer features after PCA, the computational cost of training the Logistic Regression model decreases. This makes the model training process faster and more resource-efficient, which is particularly beneficial when dealing with large datasets.\n",
    "\n",
    "Using PCA-transformed and scaled data has led to a significant improvement in model accuracy and overall performance, justifying our decision to incorporate these preprocessing steps in our modeling pipeline. The 82% accuracy stands as evidence to the effectiveness of this approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92908dd3",
   "metadata": {},
   "source": [
    "## Accuracy Scores for supervised models\n",
    "\n",
    "| Model | Parameters | Dataset | Accuracy |\n",
    "| --- | --- | --- | --- |\n",
    "| Ridge | Default | 5-Fold Validation | 0.73 (average)|\n",
    "|  | Default | Single Validation |  0.82 |\n",
    "|  | Default | Test |  0.83 |\n",
    "|  | Tuned, C = 1 | Validation |   0.82 |\n",
    "|  | Test, C = 1 | Test |  0.83 |\n",
    "| Lasso | Default | 5-Fold Validation |  0.73 (average)|\n",
    "|  | Default | Single Validation |  0.82 |\n",
    "|  | Default | Test |  0.83 |\n",
    "|  | Tuned | Single Validation |  0.82 |\n",
    "|  | Tuned | Test |  0.83 |\n",
    "| XGBoost | Tuned | Validation |  0.88 |\n",
    "|  | Tuned | Test |  0.88 |\n",
    "| Agglomerative Clustering | Tuned | Validation |  0.74 |\n",
    "|  | Tuned | Test |  0.73 |\n",
    "| DBSCAN | Tuned | Validation |  0.74 |\n",
    "|  | Tuned | Test |  0.73 |\n",
    "| AdaBoost | Default | Validation |  0.76 |\n",
    "|  | Default | Test |  0.76 |\n",
    "| SVM | Default | Validation |  0.84 |\n",
    "|  | Default | Test |  0.85 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97352699",
   "metadata": {},
   "source": [
    "The best model would be the XGboost model with a 88% accuracy. This will be the model that will be deployed with flask. The code below documents how we built the model and tuned parameters for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae71a30-46f4-4479-9b5f-7a0071d640a6",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03656369-937a-4b1e-b7ba-3b3fbe8d0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter grid\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "# initialize the XGBoost classifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# setup GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, \n",
    "                               param_grid=param_grid_xgb, \n",
    "                               scoring='accuracy', \n",
    "                               cv=3, n_jobs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6b63ce-e11e-44b6-ac6c-1c3c3eff0508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samantharivas/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=2,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 0.9, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=2,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.8, 0.9, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=2,\n",
       "             param_grid={'colsample_bytree': [0.8, 0.9, 1.0],\n",
       "                         'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.8, 0.9, 1.0]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "grid_search_xgb.fit(x_train_scaled_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db152eef-9e1b-48f3-a2d0-7d2fb37506af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Best Cross-Validation Score: 0.9020434290577409\n"
     ]
    }
   ],
   "source": [
    "# best parameters and best score\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "best_score_xgb = grid_search_xgb.best_score_\n",
    "\n",
    "print(f'Best Parameters for XGBoost: {best_params_xgb}')\n",
    "print(f'Best Cross-Validation Score: {best_score_xgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e5f422-fd7a-4030-a8c9-8926565c83d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation Accuracy: 0.8803916937434968\n",
      "XGBoost Validation Confusion Matrix:\n",
      "[[101340  15491]\n",
      " [  3246  36576]]\n",
      "XGBoost Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92    116831\n",
      "           1       0.70      0.92      0.80     39822\n",
      "\n",
      "    accuracy                           0.88    156653\n",
      "   macro avg       0.84      0.89      0.86    156653\n",
      "weighted avg       0.90      0.88      0.89    156653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on validation set\n",
    "xgb_best_model = grid_search_xgb.best_estimator_\n",
    "y_val_pred = xgb_best_model.predict(x_val_scaled_pca)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'XGBoost Validation Accuracy: {val_accuracy}')\n",
    "print('XGBoost Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('XGBoost Validation Classification Report:')\n",
    "print(val_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af6f2219-6c77-4b0a-9ad1-d1a1c26280fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test Accuracy: 0.8814201999310582\n",
      "XGBoost Test Confusion Matrix:\n",
      "[[101503  15329]\n",
      " [  3247  36575]]\n",
      "XGBoost Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92    116832\n",
      "           1       0.70      0.92      0.80     39822\n",
      "\n",
      "    accuracy                           0.88    156654\n",
      "   macro avg       0.84      0.89      0.86    156654\n",
      "weighted avg       0.90      0.88      0.89    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "y_test_pred = xgb_best_model.predict(x_test_scaled_pca)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'XGBoost Test Accuracy: {test_accuracy}')\n",
    "print('XGBoost Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('XGBoost Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "014e466a-26ca-4cce-b53d-67f667fce7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIHklEQVR4nO3dfXzO9f////sx5tj5nG1mTudcmLyRc4bMWXKSL1IMb0qiRLxJZSRnfdR6VyhlyHlvC5WzynkjFArlnZxFSM42w+zk+fvDb8e7wzaHzdjyul0vl+OS4/l6vl6v5+ux13bce50dNmOMEQAAgIW45fYAAAAA7jUCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEO6JOXPmyGazZfh68cUX78o6Dxw4oMjISB09evSuLP9OHD16VDabTf/3f/+X20PJttjYWEVGRurixYu5PZQcs2TJElWrVk2enp6y2Wzas2fPXVvX+PHjZbPZtHbt2gzHYbPZ9O677zq1JyYm6r333lOzZs1UpEgRubu7q0iRIgoLC9P777+v+Ph4p/43/655e3uratWqGjdunBISEu7att2uhQsXKioq6rb7h4WFyWazqVy5csroSww2b97s2NY5c+bk2DjT/n5l529JZGSkbDZbjo0FOYcAhHsqOjpa27Ztc3o999xzd2VdBw4c0Lhx4/JkALofxMbGaty4cfdNADp79qx69eql8uXLa82aNdq2bZsqVap019b30ksvqXbt2urfv78uXbrkaD916pQGDRqk5s2b69lnn3UaX8OGDTVs2DBVrlxZH3zwgdavX6+PPvpIoaGhGjlypAYNGpRuPV27dnX8rq1YsUJdu3bV+PHj1bt377u2bbcrqwFIknx9fXXkyBGtX78+3bTZs2fLz88vh0aH+13+3B4ArKV69eqqU6dObg/jjiQlJclmsyl/fmv++ly9elUeHh65PYwc99///ldJSUl68skn1axZsxxZ5pUrV+Tl5ZXhtPz582vu3LmqXbu2nnvuOc2dO1eS1L9/fyUlJSk6OtrpyMGTTz6pH3/8UV999ZWaNm3qtKxOnTpp7NixWr16dbr1FCtWTPXr13e8f/jhh3Xs2DEtWLBA165d+9v9LEuXLi1fX1/Nnj1bLVu2dLTHx8frk08+0RNPPKFZs2bl4gjxd8ERIOQpS5YsUYMGDeTt7S0fHx+1bt1au3fvduqza9cu9ejRQ2XLlpWnp6fKli2rxx9/XMeOHXP0mTNnjv7f//t/kqTmzZunOyxetmxZ9enTJ936w8LCFBYW5ni/ceNG2Ww2ffzxxxo+fLhKlCghu92uQ4cOSZK++uortWzZUn5+fvLy8lKjRo309ddfZ2vb0w6zr1+/XgMGDFCRIkXk5+en3r17KyEhQadPn1a3bt1UsGBBFS9eXC+++KKSkpIc86edVps6dapef/11lS5dWh4eHqpTp06GY9q6datatmwpX19feXl5qWHDhvriiy8yHNO6devUr18/BQQEyMvLS6NHj9aIESMkSSEhIY76bty4UdKNn2N4eLiKFy8uT09PVa1aVaNGjUp32qVPnz7y8fHRoUOH1K5dO/n4+KhUqVIaPny4EhMTnfomJiZq/Pjxqlq1qjw8PFSkSBE1b95csbGxjj7GGE2fPl0PPvigPD09VahQIXXt2lWHDx++Ze379Omjxo0bS5K6d+8um83mtB+sXLlSDRo0kJeXl3x9fdWqVStt27bNaRlppzq+//57de3aVYUKFVL58uVvud5q1app/PjxmjdvnlauXKlZs2Zp1apVevPNN1WmTBlHv507d2rdunV66qmn0oWfNEWKFNGTTz55y/Wl8ff3l81mU758+ZzaZ8+erZo1a8rDw0OFCxdW586d9dNPP6Wb/3bqcfbsWT311FMqVaqU7Ha7AgIC1KhRI3311VeSbvyuffHFFzp27JjTabrb0a9fP8XExDgdfVy8eLEkqUePHhnOczv7uyRt375djRo1koeHh4KDgzV69Gin37O/up2/V8i7CEC4p1JSUpScnOz0SjNx4kQ9/vjjeuCBB7R06VJ9/PHHio+PV5MmTXTgwAFHv6NHj6py5cqKiorS2rVrNWXKFJ06dUp169bVn3/+KUlq3769Jk6cKEl67733HKcA2rdvn61xjx49WsePH9fMmTP12WefKTAwUPPnz1d4eLj8/Pw0d+5cLV26VIULF1br1q2zHYKkG0cA/P39tXjxYr388stauHChBgwYoPbt26tmzZr6z3/+o4iICE2bNk3vvPNOuvnfffddrVmzRlFRUZo/f77c3NzUtm1bpw+oTZs2qUWLFrp06ZI++ugjLVq0SL6+vurQoYOWLFmSbpn9+vWTu7u7Pv74Y/3nP//RM888oyFDhkiSYmJiHPX9xz/+IUn65Zdf1K5dO3300Udas2aNhg4dqqVLl6pDhw7plp2UlKRHH31ULVu21IoVK9SvXz+99dZbmjJliqNPcnKy2rZtq9dee02PPPKIPv30U82ZM0cNGzbU8ePHHf2efvppDR06VA8//LCWL1+u6dOna//+/WrYsKHOnDmTac1feeUVvffee5Ju7Ifbtm3T9OnTJd04TdOxY0f5+flp0aJF+uijj3ThwgWFhYVp69at6ZbVpUsXVahQQZ988olmzpyZ6TrTDB8+XA0aNNCAAQM0bNgwtW3bVv3793fq8+WXX0qSHn30UZfLu5kxxvG7dvHiRa1YsUJz585Vjx495O7u7ug3adIk/fOf/1S1atUUExOjt99+Wz/88IMaNGigX375xdHvduvRq1cvLV++XK+++qrWrVunDz/8UA8//LDOnTsnSZo+fboaNWqkoKAgp1Pit6NHjx7Kly+fFi1a5Gj76KOP1LVr1wxPgd3u/n7gwAG1bNlSFy9e1Jw5czRz5kzt3r1bEyZMSLfM2/17hTzMAPdAdHS0kZThKykpyRw/ftzkz5/fDBkyxGm++Ph4ExQUZLp165bpspOTk83ly5eNt7e3efvttx3tn3zyiZFkNmzYkG6eMmXKmIiIiHTtzZo1M82aNXO837Bhg5FkmjZt6tQvISHBFC5c2HTo0MGpPSUlxdSsWdM89NBDt6iGMUeOHDGSzBtvvOFoS6vRzTXo1KmTkWTefPNNp/YHH3zQ/OMf/0i3zODgYHP16lVHe1xcnClcuLB5+OGHHW3169c3gYGBJj4+3tGWnJxsqlevbkqWLGlSU1OdxtS7d+902/DGG28YSebIkSO33NbU1FSTlJRkNm3aZCSZvXv3OqZFREQYSWbp0qVO87Rr185UrlzZ8X7evHlGkpk1a1am69m2bZuRZKZNm+bU/ttvvxlPT08zcuTIW44z7Wf9ySefONpSUlJMcHCwqVGjhklJSXG0x8fHm8DAQNOwYUNH29ixY40k8+qrr95yPRmJjY01kozdbjcnT55MN33gwIFGkvn555+d2tNqm/ZKTk52mp7Z71zbtm3N5cuXHf0uXLhgPD09Tbt27ZzmP378uLHb7aZnz55ZroePj48ZOnToLbe7ffv2pkyZMrcuzl80a9bMVKtWzRhzY9+pU6eOMcaY/fv3G0lm48aNZufOnUaSiY6Odsx3u/t79+7djaenpzl9+rRTvypVqjjt61n5e5W2XyDv4QgQ7ql58+Zp586dTq/8+fNr7dq1Sk5OVu/evZ2ODnl4eKhZs2aOUyuSdPnyZf3rX/9ShQoVlD9/fuXPn18+Pj5KSEjI8HB9Tnjsscec3sfGxur8+fOKiIhwGm9qaqratGmjnTt3Zvsum0ceecTpfdWqVSUp3dGrqlWrOp32S9OlSxen6zrS/k938+bNSklJUUJCgr799lt17dpVPj4+jn758uVTr169dOLECR08ePCW2+/K4cOH1bNnTwUFBSlfvnxyd3d3XFdz88/IZrOlOzIUGhrqtG2rV6+Wh4eH+vXrl+k6P//8c9lsNj355JNOP5OgoCDVrFnTaR+6XQcPHtTvv/+uXr16yc3tf38ufXx89Nhjj2n79u26cuWK0zxZrZUkRUVFyc3NTYmJidq8efNtz7dixQq5u7s7Xv7+/un6dOvWzfG7tnnzZv373//Wrl271KZNG8dpxm3btunq1avpTguXKlVKLVq0cBzRzEo9HnroIc2ZM0cTJkzQ9u3bMz2NlF39+vXTrl279OOPP+qjjz5S+fLlMzw9mJX9fcOGDWrZsqWKFSvm1K979+5Oy8zK3yvkXda8ihO5pmrVqhleBJ12eqJu3boZzvfXP7Y9e/bU119/rVdeeUV169aVn5+fbDab2rVrp6tXr96VcRcvXjzD8Xbt2jXTec6fPy9vb+8sr6tw4cJO7wsUKJBp+7Vr19LNHxQUlGHb9evXdfnyZcXHx8sYk26bJCk4OFiSHKcp0mTUNzOXL19WkyZN5OHhoQkTJqhSpUry8vLSb7/9pi5duqT7GXl5eaW7ENdutztt29mzZxUcHOy0H9zszJkzMsY4fXj9Vbly5W57G9Kk1SGzWqWmpurChQtOFzpnpVaS9Mknn2jp0qWKiorS8uXLNXjwYDVv3txpO0qXLi1JOnbsmCpXruxoDwsL086dOyVJ48aN04YNG9ItPyAgwOl3rkmTJgoICNDjjz+uOXPm6Omnn3a5nWmn4LJSjyVLlmjChAn68MMP9corr8jHx0edO3fW1KlTM9xHs6pp06aqWLGi3n//fS1dulRDhw7N8BqiCxcu3Pb+fu7cuUx/f/4qK3+vkHcRgJAnFC1aVJL0n//8x+niz5tdunRJn3/+ucaOHatRo0Y52hMTE3X+/PnbXp+Hh0e6i2wl6c8//3SM5a9u/sOa1uedd95xusPmrzL7IL7bTp8+nWFbgQIF5OPjo/z588vNzU2nTp1K1+/333+XpHQ1yMpzTNavX6/ff/9dGzdudLqb6k5ulw8ICNDWrVuVmpqa6YdL0aJFZbPZtGXLFtnt9nTTM2pzpUiRIpKUaa3c3NxUqFAhp/as1OrMmTMaNGiQwsLC9Nxzz+nRRx9VjRo19MwzzygmJsbRr1WrVnrppZe0cuVKhYeHO9oLFizoCDdpY70doaGhkqS9e/c6zZvZdqbtD1mpR9GiRRUVFaWoqCgdP35cK1eu1KhRo/THH39ozZo1tz3WW+nbt69efvll2Ww2RUREZNinUKFCt72/FylSJNPfn7+63b9XyNuIqcgTWrdurfz58+vXX39VnTp1MnxJNz5cjDHpPsw+/PBDpaSkOLWl9cnoqFDZsmX1ww8/OLX997//TXfqJzONGjVSwYIFdeDAgUzHm3bk5l6LiYlxOnoSHx+vzz77TE2aNFG+fPnk7e2tevXqKSYmxqk2qampmj9/vkqWLHlbz7/JrL5pAeDmn9H777+f7W1q27atrl27dsuH2z3yyCMyxujkyZMZ/jxq1KiR5fVWrlxZJUqU0MKFC50evJeQkKBly5Y57oTKroEDB+ratWuaPXu2bDabQkJCNGXKFH366aeOu5okqU6dOgoPD9esWbO0ZcuWbK8vTdoDHgMDAyVJDRo0kKenp+bPn+/U78SJE1q/fr3jdvPs1qN06dIaPHiwWrVqpe+//97Rbrfb7+iobUREhDp06KARI0aoRIkSGfbJyv7evHlzff31104XzKekpKS7MeB2/14hb+MIEPKEsmXLavz48RozZowOHz6sNm3aqFChQjpz5ox27Nghb29vjRs3Tn5+fmratKneeOMNFS1aVGXLltWmTZv00UcfqWDBgk7LrF69uiTpgw8+kK+vrzw8PBQSEqIiRYqoV69eevLJJzVo0CA99thjOnbsmKZOnaqAgIDbGq+Pj4/eeecdRURE6Pz58+ratasCAwN19uxZ7d27V2fPntWMGTNyuky3JV++fGrVqpWGDRum1NRUTZkyRXFxcRo3bpyjz6RJk9SqVSs1b95cL774ogoUKKDp06dr3759WrRo0W0dxUgLFG+//bYiIiLk7u6uypUrq2HDhipUqJAGDhyosWPHyt3dXQsWLHAcbciOxx9/XNHR0Ro4cKAOHjyo5s2bKzU1Vd9++62qVq2qHj16qFGjRnrqqafUt29f7dq1S02bNpW3t7dOnTqlrVu3Oo6sZIWbm5umTp2qJ554Qo888oiefvppJSYm6o033tDFixc1efLkbG/Txx9/rOXLl2vmzJkKCQlxtA8aNEj/+c9/0p0Kmz9/vlq3bq2HH35Yffr0UevWrRUYGKi4uDj98MMP+uqrrzK8A+rMmTPavn27JOnatWvas2ePJkyYoIIFC6pv376SbhxJeuWVV/TSSy+pd+/eevzxx3Xu3DmNGzdOHh4eGjt2bJbqcenSJTVv3lw9e/ZUlSpV5Ovrq507d2rNmjXq0qWLY2w1atRQTEyMZsyYodq1a8vNzS1L4SE4OFjLly932e929/eXX35ZK1euVIsWLfTqq6/Ky8tL7733Xrrr+W737xXyuFy8ABsWknY30c6dO2/Zb/ny5aZ58+bGz8/P2O12U6ZMGdO1a1fz1VdfOfqcOHHCPPbYY6ZQoULG19fXtGnTxuzbty/DO7uioqJMSEiIyZcvn9OdIampqWbq1KmmXLlyxsPDw9SpU8esX78+07vA/npn0F9t2rTJtG/f3hQuXNi4u7ubEiVKmPbt22faP82t7gK7uUZpd5GcPXvWqT0iIsJ4e3unW+aUKVPMuHHjTMmSJU2BAgVMrVq1zNq1a9ONYcuWLaZFixbG29vbeHp6mvr165vPPvvMqY+rn9vo0aNNcHCwcXNzc7rjLjY21jRo0MB4eXmZgIAA079/f/P999+nuzvn5m24eZv/6urVq+bVV181FStWNAUKFDBFihQxLVq0MLGxsU79Zs+eberVq+fYrvLly5vevXubXbt2ZbgNaW71s16+fLmpV6+e8fDwMN7e3qZly5bmm2++yXDMN/+cMnLy5ElTsGBBEx4enuH0w4cPG29vb9O5c2en9mvXrpl33nnHNG7c2BQsWNDkz5/fFC5c2DRp0sRMmTLFnDt3zqm/brr7y93d3ZQrV8707dvXHDp0KN16P/zwQxMaGmoKFChg/P39TceOHc3+/fuzXI9r166ZgQMHmtDQUOPn52c8PT1N5cqVzdixY01CQoKj3/nz503Xrl1NwYIFjc1mc3m31F/vAstMRneBGXN7+7sxxnzzzTemfv36xm63m6CgIDNixAjzwQcfZHjH4+38veIusLzLZkwGX6gC4G/n6NGjCgkJ0RtvvHHXvl8NAO4XXAMEAAAshwAEAAAsh1NgAADAcjgCBAAALIcABAAALIcABAAALIcHIerGE0F///13+fr6Zukx9gAAIPcYYxQfH+/yuwIzQgDSje+DKVWqVG4PAwAAZMNvv/2mkiVLZmkeApAkX19fSdKRI0fSfeM2bkhKStK6desUHh4ud3f33B5OnkSNXKNGrlEj16iRa1apUVxcnEqVKuX4HM8KApD+9+WNvr6+GX6XDm78Mnl5ecnPz+++/mW6E9TINWrkGjVyjRq5ZrUaZefyFS6CBgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlmMzxpjcHkRui4uLk7+/v8oPX6Lk/N65PZw8yZ7PaOpDKRq5I58SU2y5PZw8iRq5Ro1co0auUSPXslujo5Pb38VR5by0z+9Lly7Jz88vS/NyBAgAAFgOAQgAAFgOAQgAAFgOAQgAADiZMWOGQkND5efnJz8/PzVo0ECrV692TDfGKDIyUsHBwfL09FRYWJj279/vtIxff/1VnTt3VkBAgPz8/NStWzedOXPGqc+jjz6q0qVLy8PDQ8WLF1evXr30+++/33Jsf113sWLFJEk//fRTlrcxVwNQnz59ZLPZZLPZ5O7urnLlyunFF19UQkKCo8+yZcsUFhYmf39/+fj4KDQ0VOPHj9f58+clSadOnVLPnj1VuXJlubm5aejQobm0NQAA3B9KliypyZMna9euXdq1a5datGihjh07OkLO1KlT9eabb+rdd9/Vzp07FRQUpFatWik+Pl6SlJCQoPDwcNlsNq1fv17ffPONrl+/rg4dOig1NdWxnubNm2vp0qU6ePCgli1bpl9//VVdu3a95dj+uu4NGzZIkjp16uRY9+3K9SNAbdq00alTp3T48GFNmDBB06dP14svvihJGjNmjLp37666detq9erV2rdvn6ZNm6a9e/fq448/liQlJiYqICBAY8aMUc2aNXNzUwAAuC906NBB7dq1U6VKlVSpUiW9/vrr8vHx0fbt22WMUVRUlMaMGaMuXbqoevXqmjt3rq5cuaKFCxdKkr755hsdPXpUc+bMUY0aNVSjRg1FR0dr586dWr9+vWM9L7zwgurXr68yZcqoYcOGGjVqlLZv366kpKQMx3Xzuh944AFJ0tWrVx3rvl25HoDsdruCgoJUqlQp9ezZU0888YSWL1+uHTt2aOLEiZo2bZreeOMNNWzYUGXLllWrVq20bNkyRURESJLKli2rt99+W71795a/v38ubw0AAPeXlJQULV68WAkJCWrQoIGOHDmi06dPKzw83NHHbrerWbNmio2NlXTj4ITNZpPdbnf08fDwkJubm7Zu3Zrhes6fP68FCxaoYcOGcnd3z7BPRuuWpEaNGjnWfbtyPQDdzNPTU0lJSVqwYIF8fHw0aNCgDPsVLFjw3g4MAAAL+fHHH+Xj4yO73a6BAwfq008/1QMPPKDTp09LkuP6mzTFihVzTKtfv768vb31r3/9S1euXFFCQoJGjBih1NRUnTp1ymm+f/3rX/L29laRIkV0/PhxrVixItMxZbbugIAAx7TblT9Lve+yHTt2aOHChWrZsqV++eUXlStXLtMUeCcSExOVmJjoeB8XFydJsrsZ5ctn+edCZsjuZpz+i/SokWvUyDVq5Bo1ci27Nfrrqady5cpp586dunTpkmJiYhQREaGvvvpKycnJkqTk5GSn/ikpKY5lFCxYUIsWLdKQIUP073//W25uburevbtq1aolm83mNN/QoUPVu3dvHT9+XBMmTFCvXr20fPly2WzpH+B487rTlmOMybD/reR6APr888/l4+Pj2JiOHTvqnXfeUURERJY35nZNmjRJ48aNS9f+cq1UeXml3JV13i9eq5PqupPFUSPXqJFr1Mg1auRaVmu0atWqDNsbNWqktWvXauTIkerSpYukGzcplStXztFn37598vb2dlrGm2++qbi4OLm5ucnHx0d9+vRRaGhopuvp16+f+vfvr7feektVqlRJNz3tKE/auq9cuSJJ+vPPP9MdFXIl1wNQ8+bNNWPGDLm7uys4ONhxxKdSpUraunWrkpKScvwo0OjRozVs2DDH+7i4OJUqVUoTdrsp2T1fjq7rfmF3M3qtTqpe2eWmxFQePZ8RauQaNXKNGrlGjVzLbo32RbbOdNrbb7+tYsWKqW/fvoqMjNS1a9fUrl07SdL169cVERGhiRMnOtputmHDBl26dEkvvviiKleunGGf3377TZJUu3ZtNWvWLN30tFvg09addgbnm2++0ZQpU257O6U8EIC8vb1VoUKFdO09e/bUv//9b02fPl3PP/98uukXL17M9nVAdrvd6cKsNImpNiXzvTK3lJhq47t3XKBGrlEj16iRa9TItazWKO2Aw0svvaS2bduqVKlSio+P1+LFi7Vp0yatWbNGBQoU0NChQzVp0iRVqVJFFStW1MSJE+Xl5aVevXo5lhEdHa2qVasqICBA27Zt0/PPP68XXnhB1atXl3TjspcdO3aocePGKlSokA4fPqxXX31V5cuXV5MmTRzLqVKliiZNmqTOnTtLktO6ixcvLunG9cM9e/bMUm1yPQBlpl69eho5cqSGDx+ukydPqnPnzgoODtahQ4c0c+ZMNW7c2BGM9uzZI0m6fPmyzp49qz179qhAgQKO2+MAAMDtO3PmjHr16qVTp07J399foaGhWrNmjVq1aiVJGjlypK5evapBgwbpwoULqlevntatWydfX1/HMg4ePKjRo0fr/PnzKlu2rMaMGaMXXnjBMd3T01MxMTEaO3asEhISVLx4cbVp00aLFy92Okhx8OBBXbp0yfH+5nVL0qeffuq07tuRq98G36dPH128eFHLly/PtM/SpUv13nvvaffu3UpNTVX58uXVtWtXDRkyxHEEKKNrhcqUKaOjR4/e1jj4NnjX+PZl16iRa9TINWrkGjVyjW+Ddy1XjwDNmTPHZZ9u3bqpW7dut+yTixkOAAD8DeW55wABAADcbQQgAABgOQQgAABgObl6EXRekXYR1Z9//qkiRYrk9nDypKSkJK1atUrt2rW7K0/nvh9QI9eokWvUyDVq5JpVanQnF0FzBAgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFhOjgWgixcv5tSiAAAA7qpsBaApU6ZoyZIljvfdunVTkSJFVKJECe3duzfHBgcAAHA3ZCsAvf/++ypVqpQk6csvv9SXX36p1atXq23bthoxYkSODhAAACCn5c/OTKdOnXIEoM8//1zdunVTeHi4ypYtq3r16uXoAAEAAHJato4AFSpUSL/99pskac2aNXr44YclScYYpaSk5NzoAAAA7oJsHQHq0qWLevbsqYoVK+rcuXNq27atJGnPnj2qUKFCjg4QAAAgp2UrAL311lsqW7asfvvtN02dOlU+Pj6SbpwaGzRoUI4OEAAAIKdlKwC5u7vrxRdfTNc+dOjQOx0PAADAXZft5wB9/PHHaty4sYKDg3Xs2DFJUlRUlFasWJFjgwMAALgbshWAZsyYoWHDhqlt27a6ePGi48LnggULKioqKifHBwAAkOOyFYDeeecdzZo1S2PGjFG+fPkc7XXq1NGPP/6YY4MDAAC4G7IVgI4cOaJatWqla7fb7UpISLjjQQEAANxN2QpAISEh2rNnT7r21atX64EHHrjTMQEAANxV2boLbMSIEXr22Wd17do1GWO0Y8cOLVq0SJMmTdKHH36Y02MEAADIUdkKQH379lVycrJGjhypK1euqGfPnipRooTefvtt9ejRI6fHCAAAkKOyHICSk5O1YMECdejQQQMGDNCff/6p1NRUBQYG3o3xAQAA5LgsXwOUP39+PfPMM0pMTJQkFS1alPADAAD+VrJ1EXS9evW0e/funB4LAADAPZGta4AGDRqk4cOH68SJE6pdu7a8vb2dpoeGhubI4O61epO+VnJ+b9cdLciez2jqQ1L1yLVKTLHl9nDyJGrkGjVyjRq59neu0dHJ7XN7CPj/ZSsAde/eXZL03HPPOdpsNpuMMbLZbI4nQwMAAORF2QpAR44cyelxAAAA3DPZugaoTJkyt3wBAICMTZo0SXXr1pWvr68CAwPVqVMnHTx40KnP5cuXNXjwYJUsWVKenp6qWrWqZsyY4dTngw8+UFhYmPz8/GSz2XTx4sV06/rvf/+rjh07qmjRovLz81OjRo20YcOGW47PGKPIyEgFBwfL09NTYWFh2r9//x1vd16TrSNA8+bNu+X03r17Z2swAADc7zZt2qRnn31WdevWVXJyssaMGaPw8HAdOHDAcU3tCy+8oA0bNmj+/PkqW7as1q1bp0GDBik4OFgdO3aUJF25ckVt2rRRmzZtNHr06AzX1alTJ1WqVEnr16+Xp6enoqKi9Mgjj+jXX39VUFBQhvNMnTpVb775pubMmaNKlSppwoQJatWqlQ4ePChfX9+7U5RckK0A9Pzzzzu9T0pK0pUrV1SgQAF5eXnddgDq06eP5s6de2Mg+fOrVKlS6tKli8aNG+fYCZYtW6Z33nlHu3fvVkpKisqVK6euXbtq8ODBKly4sGJiYjRjxgzt2bNHiYmJqlatmiIjI9W6devsbBoAAHfVmjVrnN5HR0crMDBQ3333nZo2bSpJ2rZtmyIiIhQWFiZJeuqpp/T+++9r165djgA0dOhQSdLGjRszXE9cXJwOHTqk2bNnO25Omjx5sqZPn679+/dnGICMMYqKitKYMWPUpUsXSdLcuXNVrFgxLVy4UE8//fSdbn6eka1TYBcuXHB6Xb58WQcPHlTjxo21aNGiLC2rTZs2OnXqlA4fPqwJEyZo+vTpevHFFyVJY8aMUffu3VW3bl2tXr1a+/bt07Rp07R37159/PHHkqTNmzerVatWWrVqlb777js1b95cHTp04DZ9AMDfwqVLlyRJhQsXdrQ1btxYK1eu1MmTJ2WM0YYNG/Tf//43S/9z7+vrqypVqmjevHlKSEhQcnKy3n//fRUrVky1a9fOcJ4jR47o9OnTCg8Pd7TZ7XY1a9ZMsbGx2dzCvClbR4AyUrFiRU2ePFlPPvmkfv7559uez263O1Joz549tWHDBi1fvlx9+/bVxIkTFRUV5XTEqWzZsmrVqpXjXGdUVJTT8iZOnKgVK1bos88+y/Ab6wEAyCuMMRo2bJgaN26s6tWrO9r//e9/a8CAASpZsqTy588vNzc3ffjhh2rcuPFtL9tms2n16tXq2rWrfH195ebmpmLFimnNmjUqWLBghvOcPn1aklSsWDGn9mLFiunYsWNZ38A8LMcCkCTly5dPv//++x0tw9PTU0lJSVqwYIF8fHw0aNCgDPtl9sNLTU1VfHy8U5K+WWJiouNJ1tKNw4SSZHczypfPZH/w9zG7m3H6L9KjRq5RI9eokWt/5xolJSU5vX/uuef0ww8/aMOGDU7T3nrrLW3btk0xMTEqXbq0tm7dqkGDBikgIEAtW7Z0WkZycrJj2WnLSEpKkjFGgwcPVkBAgDZs2CBPT0/Nnj1bjzzyiGJjY1W8ePF040tbVnJystN40h5vc/P4c9udjCdbAWjlypVO740xOnXqlN599101atQo24PZsWOHFi5cqJYtW+qXX35RuXLl5O7unqVlTJs2TQkJCerWrVumfSZNmqRx48ala3+5Vqq8vHiG0a28Vic1t4eQ51Ej16iRa9TItb9jjVatWuX49wcffKBvv/1WEydO1A8//KAffvhB0o3/SX/55Zc1atQoubm56cSJEypbtqzq16+vl156SWPHjnVa5o8//ihJWrdunXx8fBztP/zwg1avXq358+fr4sWLunjxotq2bauVK1fq5Zdf1mOPPZZufGlHgJYtW6Zy5co52vft2ydvb2+n8ecFV65cyfa82QpAnTp1cnpvs9kUEBCgFi1aaNq0aVla1ueffy4fHx9H2uzYsaPeeecdRUREyGbL2hM+Fy1apMjISK1YseKW3082evRoDRs2zPE+Li5OpUqV0oTdbkp2z5eldVqF3c3otTqpemWXmxJT/15PXr1XqJFr1Mg1auTa37lG+yJbyxijoUOHas+ePdq8ebMqVqzo1CcuLk7Jycl66KGH1KZNG0f7559/Lklq166dU/+0m4bCw8MdZ0eSkpK0Y8cOSTeutf1rMPLx8VHFihXTLUf63y3w165dc0y/fv26IiIiNHHixAznyU1pZ3CyI1sBKDU151J38+bNNWPGDLm7uys4ONhxxKdSpUraunWrkpKSbuso0JIlS/TPf/5Tn3zyiR5++OFb9rXb7bLb7enaE1NtSv6bPVb9XktMtf3tHj1/r1Ej16iRa9TItb9jjdzd3TVo0CAtXLhQK1asUOHChXXu3DlJkr+/vzw9PVWkSBE1a9ZMo0ePlq+vr8qUKaNNmzZp/vz5evPNNx2fiadPn9bp06d19OhRSdLPP/8sX19flS5d2nEBdKFChdS/f3+9+uqr8vT01KxZs3T06FE9+uijjuVUqVJFkyZNUufOnSXduLts0qRJqlKliipWrKiJEyfKy8tLvXr1yvJZmbvtTsaTrbvAxo8fn+Fhp6tXr2r8+PFZWpa3t7cqVKigMmXKOG1Iz549dfnyZU2fPj3D+f76wKdFixapT58+Wrhwodq353tWAAB514wZM3Tp0iWFhYWpePHijteSJUscfRYvXqy6devqiSee0AMPPKDJkyfr9ddf18CBAx19Zs6cqVq1amnAgAGSpKZNm6pWrVqOy1T8/Pz0+eef6/Lly2rRooXq1KmjrVu3asWKFapZs6ZjOQcPHnTciSZJI0eO1NChQzVo0CDVqVNHJ0+e1Lp16+6rZwBJ2TwCNG7cOA0cOFBeXl5O7VeuXNG4ceP06quv3vHA6tWrp5EjR2r48OE6efKkOnfurODgYB06dEgzZ85U48aN9fzzz2vRokXq3bu33n77bdWvX99x/tLT01P+/v53PA4AAHKSMa4v3g4KClJ0dPQt+0RGRioyMjLDaWkXB9euXVtr167N0nhsNtstl32/yNYRoLQvPb3Z3r17b3n3VVZNmTJFCxcu1LfffqvWrVurWrVqGjZsmEJDQxURESFJev/995WcnKxnn33WKUnf/LBGAACANFk6AlSoUCHZbDbZbDZVqlTJKQSlpKTo8uXLTofnXJkzZ47LPt26dbvlHV2ZPQETAAAgM1kKQFFRUTLGqF+/fho3bpzTKaYCBQqobNmyatCgQY4PEgAAICdlKQClnXYKCQlRw4YN89zV4AAAALcjWxdBN2vWzPHvq1evpnsSo5+f352NKpd8O7qlihQpktvDyJOSkpK0atUq7YtsTfDNBDVyjRq5Ro1co0bICdm6CPrKlSsaPHiwAgMD5ePjo0KFCjm9AAAA8rJsBaARI0Zo/fr1mj59uux2uz788EONGzdOwcHBmjdvXk6PEQAAIEdl6xTYZ599pnnz5iksLEz9+vVTkyZNHA8zXLBggZ544omcHicAAECOydYRoPPnzyskJETSjet9zp8/L0lq3LixNm/enHOjAwAAuAuyFYDKlSvn+O6RBx54QEuXLpV048hQ2hexAQAA5FXZCkB9+/bV3r17Jd34ZvW0a4FeeOEFjRgxIkcHCAAAkNOydQ3QCy+84Ph38+bN9fPPP2vXrl0qX7680xesAQAA5EXZCkB/de3aNZUuXVqlS5fOifEAAADcddk6BZaSkqLXXntNJUqUkI+Pjw4fPixJeuWVV/TRRx/l6AABAAByWrYC0Ouvv645c+Zo6tSpKlCggKO9Ro0a+vDDD3NscAAAAHdDtgLQvHnz9MEHH+iJJ55Qvnz5HO2hoaH6+eefc2xwAAAAd0O2AtDJkydVoUKFdO2pqanpvhcMAAAgr8lWAKpWrZq2bNmSrv2TTz5RrVq17nhQAAAAd1O27gIbO3asevXqpZMnTyo1NVUxMTE6ePCg5s2bp88//zynxwgAAJCjsnQE6PDhwzLGqEOHDlqyZIlWrVolm82mV199VT/99JM+++wztWrV6m6NFQAAIEdk6QhQxYoVderUKQUGBqp169aaPXu2Dh06pKCgoLs1PgAAgByXpSNAxhin96tXr9aVK1dydEAAAAB3W7Yugk5zcyACAAD4O8hSALLZbLLZbOnaAAAA/k6ydA2QMUZ9+vSR3W6XdON7wAYOHChvb2+nfjExMTk3QgAAgByWpQAUERHh9P7JJ5/M0cEAAADcC1kKQNHR0XdrHAAAAPfMHV0EDQAA8HdEAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJaTP7cHkJfUm/S1kvN75/Yw8iR7PqOpD0nVI9cqMcWW28PJk6iRa9TINavX6Ojk9rk9BFgER4AAAIDlEIAAAIDlEIAAAIDlEIAAAHnKpEmTVLduXfn6+iowMFCdOnXSwYMHM+3/9NNPy2azKSoqKl17+fLl5enpqYCAAHXs2FE///yzU59HH31UpUuXloeHh4oXL65evXrp999/v+X4jDGKjIxUcHCwPD09FRYWpv3792d7e5E7cjUA9enTRzabTTabTe7u7ipXrpxefPFFJSQkOPosW7ZMYWFh8vf3l4+Pj0JDQzV+/HidP39ekrR161Y1atRIRYoUkaenp6pUqaK33nortzYJAHCHNm3apGeffVbbt2/Xl19+qeTkZIWHhzt9NqRZvny5vv32WwUHB6ebVrt2bUVHR+unn37S2rVrZYxReHi4UlJSHH2aN2+upUuX6uDBg1q2bJl+/fVXde3a9Zbjmzp1qt588029++672rlzp4KCgtSqVSvFx8ff+cbjnsn1u8DatGmj6OhoJSUlacuWLerfv78SEhI0Y8YMjRkzRlOmTNELL7ygiRMnKjg4WL/88otmzpypjz/+WM8//7y8vb01ePBghYaGytvbW1u3btXTTz8tb29vPfXUU7m9eQCALFqzZo3T++joaAUGBuq7775T06ZNHe0nT57U4MGDtXbtWrVvn/7usb9+BpQtW1YTJkxQzZo1dfToUZUvX16S9MILLzj6lClTRqNGjVKnTp2UlJQkd3f3dMs0xigqKkpjxoxRly5dJElz585VsWLFtHDhQj399NN3tvG4Z3I9ANntdgUFBUmSevbsqQ0bNmj58uXq27evJk6cqKioKD3//POO/mXLllWrVq108eJFSVKtWrVUq1Ytp+kxMTHasmULAQgA7gOXLl2SJBUuXNjRlpqaqr59+2rEiBGqVq2ay2UkJCQoOjpaISEhKlWqVIZ9zp8/rwULFqhhw4YZhh9JOnLkiE6fPq3w8HBHm91uV7NmzRQbG0sA+hvJ9QB0M09PTyUlJWnBggXy8fHRoEGDMuxXsGDBDNt3796t2NhYTZgwIdN1JCYmKjEx0fE+Li5OkmR3M8qXz2R/8Pcxu5tx+i/So0auUSPXrF6jpKQkp/fGGA0dOlSNGjVS5cqVlZSUpKSkJMXExMjNzU3PPPOMY56UlJR088+cOVOjR49WQkKCKleurFWrVslmszn1Gz16tGbMmKErV66oXr16Wr58ebrlpDlx4oSkG2Hsr30CAgJ0/PjxTOe719LGkVfGc7fcyfbZjDG59lvWp08fXbx4UcuXL5ck7dixQ+3atVPLli0VHx+vkydPau/evbe1rJIlS+rs2bNKTk5WZGSkXnnllUz7RkZGaty4cenaFy5cKC8vr2xtCwAg573//vvatWuXJk2apKJFi0qSDh06pAkTJujNN990HBUaMGCAOnTooEcffdRp/oSEBF26dEkXLlzQ8uXLde7cOU2ePFkFChRw9ImLi1N8fLzOnj2rJUuWyMvLSy+//LJstvQPovz55581atQozZ492+mI1Hvvvac///xTY8eOvRtlQCauXLminj176tKlS/Lz88vSvLkegObPny8PDw8lJycrKSlJHTt21MyZMxUREaFTp05pz549t7WsI0eO6PLly9q+fbtGjRqld999V48//niGfTM6AlSqVCk9MGKxkt15EnRG7G5Gr9VJ1Su73JSYar2n094OauQaNXLN6jXaF9na8e+hQ4dq5cqV+vrrrxUSEuJof+uttzRq1Ci5uf3vPp6UlBS5ubmpVKlS+uWXXzJc9vXr1xUYGKiZM2eqR48eGfY5ceKEypUrp82bN6t+/frpph8+fFhVqlTRt99+63T5RZcuXVSwYEHNnj07y9t8NyQlJenLL79Uq1atMj2ddz+Ii4tT0aJFsxWAcv0UWPPmzTVjxgy5u7srODjY8YOqVKmStm7dmumFaDdL++WoUaOGzpw5o8jIyEwDkN1ul91uT9eemGpTsgUfPZ8Viak2Sz6ePyuokWvUyDWr1sjd3V3GGA0ZMkTLly/Xxo0bVbFiRac+vXv3loeHh5o0aeL4fGjdurV69eqlvn37ZvqZYYyRMUYpKSmZ9smf/8bHYmZ9KlWqpKCgIG3cuFEPPfSQpBvBasuWLZoyZUqeCxvu7u55bkw56U62LdefA+Tt7a0KFSqoTJkyThvSs2dPXb58WdOnT89wvrSLoDNijHE6wgMA+Pt49tlnNX/+fC1cuFC+vr46ffq0Tp8+ratXr0qSihQpojJlyqh69eqOl7u7u4KCglS5cmVJN47UTJo0Sd99952OHz+ubdu2qVu3bvL09FS7du0k3bjs4t1339WePXt07NgxbdiwQT179lT58uXVoEEDx3iqVKmiTz/9VJJks9k0dOhQTZw4UZ9++qn27dunPn36yMvLSz179rzHlcKdyPUjQJmpV6+eRo4cqeHDh+vkyZPq3LmzgoODdejQIc2cOVONGzfW888/r/fee0+lS5dWlSpVJN14LtD//d//aciQIbm8BQCA7JgxY4YkKSwszKk9Ojpaffr0ua1leHh4aMuWLYqKitKFCxdUrFgxNW3aVLGxsQoMDJR046abmJgYjR07VgkJCSpevLjatGmjxYsXO50lOHjwoONONEkaOXKkrl69qkGDBunChQuqV6+e1q1bJ19f3zvbcNxTeTYASdKUKVNUu3Ztvffee5o5c6ZSU1NVvnx5de3aVREREZJu3Ao5evRoHTlyRPnz51f58uU1efJkbkUEgL+p7FyaevToUaf3wcHBWrVq1S3nqVGjhtavX5/l8dhsNkVGRioyMjKrw0QekqsBaM6cOS77dOvWTd26dct0+pAhQzjaAwAAsiTXrwECAAC41whAAADAcghAAADAcvL0RdD32rejW6pIkSK5PYw8KSkpSatWrdK+yNb39TMl7gQ1co0auUaNgHuDI0AAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMByCEAAAMBy8uf2APICY4wkKT4+Xu7u7rk8mrwpKSlJV65cUVxcHDXKBDVyjRq5Ro1co0auWaVGcXFxkv73OZ4VBCBJ586dkySFhITk8kgAAEBWxcfHy9/fP0vzEIAkFS5cWJJ0/PjxLBfQKuLi4lSqVCn99ttv8vPzy+3h5EnUyDVq5Bo1co0auWaVGhljFB8fr+Dg4CzPSwCS5OZ241Iof3//+3pHyQl+fn7UyAVq5Bo1co0auUaNXLNCjbJ74IKLoAEAgOUQgAAAgOUQgCTZ7XaNHTtWdrs9t4eSZ1Ej16iRa9TINWrkGjVyjRq5ZjPZuXcMAADgb4wjQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQJKmT5+ukJAQeXh4qHbt2tqyZUtuD+meiIyMlM1mc3oFBQU5phtjFBkZqeDgYHl6eiosLEz79+93WkZiYqKGDBmiokWLytvbW48++qhOnDhxrzclx2zevFkdOnRQcHCwbDabli9f7jQ9p2py4cIF9erVS/7+/vL391evXr108eLFu7x1OcNVjfr06ZNuv6pfv75Tn/u5RpMmTVLdunXl6+urwMBAderUSQcPHnTqY/X96HZqZPX9aMaMGQoNDXU8yLBBgwZavXq1Y7rV96EcYSxu8eLFxt3d3cyaNcscOHDAPP/888bb29scO3Yst4d2140dO9ZUq1bNnDp1yvH6448/HNMnT55sfH19zbJly8yPP/5ounfvbooXL27i4uIcfQYOHGhKlChhvvzyS/P999+b5s2bm5o1a5rk5OTc2KQ7tmrVKjNmzBizbNkyI8l8+umnTtNzqiZt2rQx1atXN7GxsSY2NtZUr17dPPLII/dqM++IqxpFRESYNm3aOO1X586dc+pzP9eodevWJjo62uzbt8/s2bPHtG/f3pQuXdpcvnzZ0cfq+9Ht1Mjq+9HKlSvNF198YQ4ePGgOHjxoXnrpJePu7m727dtnjGEfygmWD0APPfSQGThwoFNblSpVzKhRo3JpRPfO2LFjTc2aNTOclpqaaoKCgszkyZMdbdeuXTP+/v5m5syZxhhjLl68aNzd3c3ixYsdfU6ePGnc3NzMmjVr7urY74WbP9xzqiYHDhwwksz27dsdfbZt22YkmZ9//vkub1XOyiwAdezYMdN5rFajP/74w0gymzZtMsawH2Xk5hoZw36UkUKFCpkPP/yQfSiHWPoU2PXr1/Xdd98pPDzcqT08PFyxsbG5NKp765dfflFwcLBCQkLUo0cPHT58WJJ05MgRnT592qk2drtdzZo1c9Tmu+++U1JSklOf4OBgVa9e/b6sX07VZNu2bfL391e9evUcferXry9/f//7pm4bN25UYGCgKlWqpAEDBuiPP/5wTLNajS5duiTpf1+6zH6U3s01SsN+dENKSooWL16shIQENWjQgH0oh1g6AP35559KSUlRsWLFnNqLFSum06dP59Ko7p169epp3rx5Wrt2rWbNmqXTp0+rYcOGOnfunGP7b1Wb06dPq0CBAipUqFCmfe4nOVWT06dPKzAwMN3yAwMD74u6tW3bVgsWLND69es1bdo07dy5Uy1atFBiYqIka9XIGKNhw4apcePGql69uiT2o5tlVCOJ/UiSfvzxR/n4+Mhut2vgwIH69NNP9cADD7AP5RC+DV6SzWZzem+MSdd2P2rbtq3j3zVq1FCDBg1Uvnx5zZ0713GxYXZqc7/XLydqklH/+6Vu3bt3d/y7evXqqlOnjsqUKaMvvvhCXbp0yXS++7FGgwcP1g8//KCtW7emm8Z+dENmNWI/kipXrqw9e/bo4sWLWrZsmSIiIrRp0ybHdPahO2PpI0BFixZVvnz50iXdP/74I12ytgJvb2/VqFFDv/zyi+NusFvVJigoSNevX9eFCxcy7XM/yamaBAUF6cyZM+mWf/bs2fuybsWLF1eZMmX0yy+/SLJOjYYMGaKVK1dqw4YNKlmypKOd/eh/MqtRRqy4HxUoUEAVKlRQnTp1NGnSJNWsWVNvv/02+1AOsXQAKlCggGrXrq0vv/zSqf3LL79Uw4YNc2lUuScxMVE//fSTihcvrpCQEAUFBTnV5vr169q0aZOjNrVr15a7u7tTn1OnTmnfvn33Zf1yqiYNGjTQpUuXtGPHDkefb7/9VpcuXbov63bu3Dn99ttvKl68uKT7v0bGGA0ePFgxMTFav369QkJCnKazH7muUUasth9lxBijxMRE9qGcck8vuc6D0m6D/+ijj8yBAwfM0KFDjbe3tzl69GhuD+2uGz58uNm4caM5fPiw2b59u3nkkUeMr6+vY9snT55s/P39TUxMjPnxxx/N448/nuFtliVLljRfffWV+f77702LFi3+1rfBx8fHm927d5vdu3cbSebNN980u3fvdjwWIadq0qZNGxMaGmq2bdtmtm3bZmrUqPG3ufX0VjWKj483w4cPN7GxsebIkSNmw4YNpkGDBqZEiRKWqdEzzzxj/P39zcaNG51u4b5y5Yqjj9X3I1c1Yj8yZvTo0Wbz5s3myJEj5ocffjAvvfSScXNzM+vWrTPGsA/lBMsHIGOMee+990yZMmVMgQIFzD/+8Q+nWzHvZ2nPjXB3dzfBwcGmS5cuZv/+/Y7pqampZuzYsSYoKMjY7XbTtGlT8+OPPzot4+rVq2bw4MGmcOHCxtPT0zzyyCPm+PHj93pTcsyGDRuMpHSviIgIY0zO1eTcuXPmiSeeML6+vsbX19c88cQT5sKFC/doK+/MrWp05coVEx4ebgICAoy7u7spXbq0iYiISLf993ONMqqNJBMdHe3oY/X9yFWN2I+M6devn+NzKSAgwLRs2dIRfoxhH8oJNmOMuXfHmwAAAHKfpa8BAgAA1kQAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAApAn9OnTRzabLd3r0KFDuT00APeh/Lk9AABI06ZNG0VHRzu1BQQE5NJonCUlJcnd3T23hwEgh3AECECeYbfbFRQU5PTKly9fhn2PHTumDh06qFChQvL29la1atW0atUqx/T9+/erffv28vPzk6+vr5o0aaJff/1VkpSamqrx48erZMmSstvtevDBB7VmzRrHvEePHpXNZtPSpUsVFhYmDw8PzZ8/X5IUHR2tqlWrysPDQ1WqVNH06dPvYkUA3C0cAQLwt/Tss8/q+vXr2rx5s7y9vXXgwAH5+PhIkk6ePKmmTZsqLCxM69evl5+fn7755hslJydLkt5++21NmzZN77//vmrVqqXZs2fr0Ucf1f79+1WxYkXHOv71r39p2rRpio6Olt1u16xZszR27Fi9++67qlWrlnbv3q0BAwbI29tbERERuVIHANmU29/GCgDGGBMREWHy5ctnvL29Ha+uXbtm2r9GjRomMjIyw2mjR482ISEh5vr16xlODw4ONq+//rpTW926dc2gQYOMMcYcOXLESDJRUVFOfUqVKmUWLlzo1Pbaa6+ZBg0auNw+AHkLR4AA5BnNmzfXjBkzHO+9vb0z7fvcc8/pmWee0bp16/Twww/rscceU2hoqCRpz549atKkSYbX7MTFxen3339Xo0aNnNobNWqkvXv3OrXVqVPH8e+zZ8/qt99+0z//+U8NGDDA0Z6cnCx/f/+sbSiAXEcAApBneHt7q0KFCrfVt3///mrdurW++OILrVu3TpMmTdK0adM0ZMgQeXp6upzfZrM5vTfGpGv7awBLTU2VJM2aNUv16tVz6pfZdUoA8i4uggbwt1WqVCkNHDhQMTExGj58uGbNmiVJCg0N1ZYtW5SUlJRuHj8/PwUHB2vr1q1O7bGxsapatWqm6ypWrJhKlCihw4cPq0KFCk6vkJCQnN0wAHcdR4AA/C0NHTpUbdu2VaVKlXThwgWtX7/eEWAGDx6sd955Rz169NDo0aPl7++v7du366GHHlLlypU1YsQIjR07VuXLl9eDDz6o6Oho7dmzRwsWLLjlOiMjI/Xcc8/Jz89Pbdu2VWJionbt2qULFy5o2LBh92KzAeQQAhCAv6WUlBQ9++yzOnHihPz8/NSmTRu99dZbkqQiRYpo/fr1GjFihJo1a6Z8+fLpwQcfdFz389xzzykuLk7Dhw/XH3/8oQceeEArV650ugMsI/3795eXl5feeOMNjRw5Ut7e3qpRo4aGDh16tzcXQA6zGWNMbg8CAADgXuIaIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDkEIAAAYDn/HwVSdaq7NHKqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_importance(xgb_best_model, importance_type='weight')\n",
    "plt.title('Feature Importance for XGBoost Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a78aa14-1996-4384-a215-45c5b478b1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost model saved at: models/xgb_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# ensure the models folder exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# save tuned XGBoost model\n",
    "xgb_best_model_path = 'xgb_best_model.joblib'\n",
    "joblib.dump(xgb_best_model, xgb_best_model_path)\n",
    "\n",
    "print(f'Tuned XGBoost model saved at: {xgb_best_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676af1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48383090-e2ac-4074-b60a-5bd29a2ced41",
   "metadata": {},
   "source": [
    "##  Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea3ceff2-3861-4b8b-9f87-937eac74a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce datasize for agglomerative clustering and DBSCAN \n",
    "\n",
    "# function to reduce dataset size\n",
    "def reduce_dataset(x, y, sample_size):\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(x.shape[0], size=sample_size, replace=False)\n",
    "    return x[indices], y[indices]\n",
    "\n",
    "# convert data to np.float32\n",
    "x_train_np = x_train_scaled_pca.astype(np.float32).to_numpy()\n",
    "x_val_np = x_val_scaled_pca.astype(np.float32).to_numpy()\n",
    "x_test_np = x_test_scaled_pca.astype(np.float32).to_numpy()\n",
    "\n",
    "# sample the data\n",
    "sample_size = 25000\n",
    "x_train_sampled, y_train_sampled = reduce_dataset(x_train_np, y_train, sample_size)\n",
    "x_val_sampled, y_val_sampled = reduce_dataset(x_val_np, y_val, sample_size)\n",
    "x_test_sampled, y_test_sampled = reduce_dataset(x_test_np, y_test, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c711cb3-b246-469b-8616-5e657d1554b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter grid for the number of clusters\n",
    "param_grid_agg = {'n_clusters': [2, 3, 4, 5, 6]}\n",
    "\n",
    "# initialize the AgglomerativeClustering model\n",
    "agg_model = AgglomerativeClustering()\n",
    "\n",
    "# define a custom scoring function using silhouette score\n",
    "def silhouette_scorer(estimator, X):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    return score\n",
    "\n",
    "# setup GridSearchCV with silhouette scorer\n",
    "grid_search_agg = GridSearchCV(estimator=agg_model, param_grid=param_grid_agg, \n",
    "                               scoring=silhouette_scorer, cv=3, n_jobs=-2, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a893c73-5a36-4479-b4f5-987cb20b5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   3.5s\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=AgglomerativeClustering(), n_jobs=-2,\n",
       "             param_grid={&#x27;n_clusters&#x27;: [2, 3, 4, 5, 6]},\n",
       "             scoring=&lt;function silhouette_scorer at 0x17361b550&gt;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=AgglomerativeClustering(), n_jobs=-2,\n",
       "             param_grid={&#x27;n_clusters&#x27;: [2, 3, 4, 5, 6]},\n",
       "             scoring=&lt;function silhouette_scorer at 0x17361b550&gt;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: AgglomerativeClustering</label><div class=\"sk-toggleable__content fitted\"><pre>AgglomerativeClustering()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;AgglomerativeClustering<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.AgglomerativeClustering.html\">?<span>Documentation for AgglomerativeClustering</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>AgglomerativeClustering()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=AgglomerativeClustering(), n_jobs=-2,\n",
       "             param_grid={'n_clusters': [2, 3, 4, 5, 6]},\n",
       "             scoring=<function silhouette_scorer at 0x17361b550>, verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "grid_search_agg.fit(x_train_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca306139-c2de-4dc4-9bf2-41dbe0a340e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Agglomerative Clustering: {'n_clusters': 2}\n",
      "Best Cross-Validation Score: 0.9882101019223531\n"
     ]
    }
   ],
   "source": [
    "# best parameters and best score\n",
    "best_params_agg = grid_search_agg.best_params_\n",
    "best_score_agg = grid_search_agg.best_score_\n",
    "\n",
    "print(f'Best Parameters for Agglomerative Clustering: {best_params_agg}')\n",
    "print(f'Best Cross-Validation Score: {best_score_agg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e16509e-785b-4823-b5a1-12ee4eec882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative Clustering Validation Accuracy: 0.74756\n",
      "Agglomerative Clustering Validation Confusion Matrix:\n",
      "[[18685     0]\n",
      " [ 6311     4]]\n",
      "Agglomerative Clustering Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     18685\n",
      "           1       1.00      0.00      0.00      6315\n",
      "\n",
      "    accuracy                           0.75     25000\n",
      "   macro avg       0.87      0.50      0.43     25000\n",
      "weighted avg       0.81      0.75      0.64     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on validation set\n",
    "agg_best_model = grid_search_agg.best_estimator_\n",
    "y_val_pred = agg_best_model.fit_predict(x_val_sampled)\n",
    "val_accuracy = accuracy_score(y_val_sampled, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val_sampled, y_val_pred)\n",
    "val_classification_report = classification_report(y_val_sampled, y_val_pred)\n",
    "\n",
    "print(f'Agglomerative Clustering Validation Accuracy: {val_accuracy}')\n",
    "print('Agglomerative Clustering Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Agglomerative Clustering Validation Classification Report:')\n",
    "print(val_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9337e65-6820-4861-91bf-fca8ec27aa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative Clustering Test Accuracy: 0.73552\n",
      "Agglomerative Clustering Test Confusion Matrix:\n",
      "[[18375     2]\n",
      " [ 6610    13]]\n",
      "Agglomerative Clustering Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85     18377\n",
      "           1       0.87      0.00      0.00      6623\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.80      0.50      0.43     25000\n",
      "weighted avg       0.77      0.74      0.62     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "y_test_pred = agg_best_model.fit_predict(x_test_sampled)\n",
    "test_accuracy = accuracy_score(y_test_sampled, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test_sampled, y_test_pred)\n",
    "test_classification_report = classification_report(y_test_sampled, y_test_pred)\n",
    "\n",
    "print(f'Agglomerative Clustering Test Accuracy: {test_accuracy}')\n",
    "print('Agglomerative Clustering Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Agglomerative Clustering Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e131a1d6-d738-4f68-9324-669e93b56fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the silhouette scores for each sample\n",
    "agglo_labels = y_val_pred \n",
    "silhouette_avg_agglo = silhouette_score(x_val_sampled, agglo_labels)\n",
    "sample_silhouette_values_agglo = silhouette_samples(x_val_sampled, agglo_labels)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "fig.set_size_inches(18, 7)\n",
    "\n",
    "# silhouette coefficient - focus on 0 to 1\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "ax1.set_ylim([0, len(x_val_sampled) + (len(np.unique(agglo_labels)) + 1) * 10])\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(len(np.unique(agglo_labels))):\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values_agglo[agglo_labels == i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = cm.nipy_spectral(float(i) / len(np.unique(agglo_labels)))\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    # compute  new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax1.set_title(\"Silhouette plot for Agglomerative Clustering\")\n",
    "ax1.set_xlabel(\"Silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "# vertical line for average silhouette score of all the values\n",
    "ax1.axvline(x=silhouette_avg_agglo, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax1.set_yticks([]) \n",
    "ax1.set_xticks(np.arange(-0.1, 1.1, 0.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b257a153-d59a-48f1-a28a-51d78b4ca626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Agglomerative Clustering model saved at: models/agg_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# save tuned Agglomerative Clustering model\n",
    "agg_best_model_path = 'models/agg_best_model.pkl'\n",
    "joblib.dump(agg_best_model, agg_best_model_path)\n",
    "\n",
    "print(f'Tuned Agglomerative Clustering model saved at: {agg_best_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bb36c-4314-41ad-9aff-21fb083300c1",
   "metadata": {},
   "source": [
    "## Density-Based Spatial Clustering of Applications with Noise (DBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca65039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define silhouette scorer\n",
    "class SilhouetteScorer:\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __call__(self, estimator, X=None):\n",
    "        labels = estimator.fit_predict(self.X)\n",
    "        num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        if num_clusters > 1:\n",
    "            return silhouette_score(self.X, labels)\n",
    "        else:\n",
    "            return -1 \n",
    "        \n",
    "# define the parameter grid for DBSCAN\n",
    "param_grid_dbscan = {\n",
    "    'eps': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    'min_samples': [3, 5, 7, 10, 15]\n",
    "}\n",
    "\n",
    "# initialize the DBSCAN model\n",
    "dbscan_model = DBSCAN()\n",
    "\n",
    "# create the silhouette scorer\n",
    "silhouette_scorer = SilhouetteScorer(X=x_train_sampled)\n",
    "\n",
    "# setup GridSearchCV\n",
    "grid_search_dbscan = GridSearchCV(estimator=dbscan_model, param_grid=param_grid_dbscan, \n",
    "                                  scoring=silhouette_scorer, cv=3, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1882dedc-4ab4-457c-aff4-792adb44facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n",
      "[CV] END .......................................n_clusters=2; total time=  28.7s\n",
      "[CV] END .......................................n_clusters=6; total time=  41.2s\n",
      "[CV] END .............................eps=0.2, min_samples=5; total time=  17.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samantharivas/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................................n_clusters=2; total time=  27.9s\n",
      "[CV] END .......................................n_clusters=5; total time=  41.9s\n",
      "[CV] END .............................eps=0.2, min_samples=5; total time=  15.6s\n",
      "[CV] END .............................eps=0.2, min_samples=7; total time=  15.9s\n",
      "[CV] END .......................................n_clusters=3; total time=  27.4s\n",
      "[CV] END .......................................n_clusters=5; total time=  37.6s\n",
      "[CV] END .......................................n_clusters=6; total time=   7.7s\n",
      "[CV] END .............................eps=0.2, min_samples=3; total time=  17.5s\n",
      "[CV] END ............................eps=0.2, min_samples=10; total time=  14.6s\n",
      "[CV] END .......................................n_clusters=3; total time=  28.4s\n",
      "[CV] END .......................................n_clusters=6; total time=  41.2s\n",
      "[CV] END .............................eps=0.2, min_samples=5; total time=  17.7s\n",
      "[CV] END ............................eps=0.2, min_samples=10; total time=  14.8s\n",
      "[CV] END .......................................n_clusters=4; total time=  28.0s\n",
      "[CV] END .......................................n_clusters=5; total time=  40.8s\n",
      "[CV] END .............................eps=0.2, min_samples=3; total time=  17.9s\n",
      "[CV] END ............................eps=0.2, min_samples=15; total time=  15.1s\n",
      "[CV] END .......................................n_clusters=2; total time=  27.2s\n",
      "[CV] END .......................................n_clusters=4; total time=  39.1s\n",
      "[CV] END .............................eps=0.2, min_samples=3; total time=  18.0s\n",
      "[CV] END .............................eps=0.3, min_samples=3; total time=  16.3s\n",
      "[CV] END .......................................n_clusters=3; total time=  26.9s\n",
      "[CV] END .......................................n_clusters=4; total time=  41.0s\n",
      "[CV] END .............................eps=0.2, min_samples=7; total time=  17.9s\n",
      "[CV] END ............................eps=0.2, min_samples=15; total time=  15.6s\n",
      "[CV] END .............................eps=0.3, min_samples=5; total time=  15.7s\n",
      "[CV] END .............................eps=0.3, min_samples=5; total time=  16.6s\n",
      "[CV] END .............................eps=0.4, min_samples=3; total time=  15.9s\n",
      "[CV] END .............................eps=0.4, min_samples=7; total time=  16.7s\n",
      "[CV] END .............................eps=0.3, min_samples=7; total time=  16.2s\n",
      "[CV] END .............................eps=0.4, min_samples=3; total time=  16.3s\n",
      "[CV] END ............................eps=0.4, min_samples=10; total time=  16.2s\n",
      "[CV] END ............................eps=0.2, min_samples=10; total time=  16.1s\n",
      "[CV] END .............................eps=0.3, min_samples=7; total time=  16.5s\n",
      "[CV] END ............................eps=0.3, min_samples=15; total time=  15.6s\n",
      "[CV] END .............................eps=0.4, min_samples=7; total time=  16.6s\n",
      "[CV] END .............................eps=0.5, min_samples=3; total time=  17.1s\n",
      "[CV] END .............................eps=0.5, min_samples=7; total time=  17.2s\n",
      "[CV] END .............................eps=0.5, min_samples=3; total time=  17.0s\n",
      "[CV] END ............................eps=0.5, min_samples=10; total time=  16.9s\n",
      "[CV] END .............................eps=0.6, min_samples=3; total time=  16.8s\n",
      "[CV] END ............................eps=0.6, min_samples=10; total time=  17.5s\n",
      "[CV] END .............................eps=0.7, min_samples=3; total time=  18.6s\n",
      "[CV] END ............................eps=0.7, min_samples=10; total time=  18.6s\n",
      "[CV] END .............................eps=0.8, min_samples=5; total time=  18.2s\n",
      "[CV] END ............................eps=0.8, min_samples=10; total time=  16.8s\n",
      "[CV] END .............................eps=0.6, min_samples=3; total time=  17.5s\n",
      "[CV] END ............................eps=0.6, min_samples=10; total time=  18.2s\n",
      "[CV] END .............................eps=0.7, min_samples=5; total time=  17.5s\n",
      "[CV] END ............................eps=0.7, min_samples=10; total time=  18.6s\n",
      "[CV] END .............................eps=0.8, min_samples=5; total time=  19.5s\n",
      "[CV] END ............................eps=0.8, min_samples=15; total time=  16.3s\n",
      "[CV] END .............................eps=0.5, min_samples=3; total time=  17.4s\n",
      "[CV] END ............................eps=0.5, min_samples=10; total time=  16.7s\n",
      "[CV] END .............................eps=0.6, min_samples=5; total time=  17.7s\n",
      "[CV] END ............................eps=0.6, min_samples=10; total time=  17.8s\n",
      "[CV] END .............................eps=0.7, min_samples=5; total time=  18.2s\n",
      "[CV] END ............................eps=0.7, min_samples=15; total time=  17.7s\n",
      "[CV] END .............................eps=0.8, min_samples=5; total time=  19.6s\n",
      "[CV] END ............................eps=0.8, min_samples=15; total time=  16.3s\n",
      "[CV] END .............................eps=0.3, min_samples=3; total time=  15.9s\n",
      "[CV] END ............................eps=0.3, min_samples=10; total time=  15.4s\n",
      "[CV] END .............................eps=0.4, min_samples=3; total time=  15.5s\n",
      "[CV] END ............................eps=0.4, min_samples=10; total time=  15.6s\n",
      "[CV] END .............................eps=0.5, min_samples=5; total time=  17.1s\n",
      "[CV] END ............................eps=0.5, min_samples=10; total time=  16.1s\n",
      "[CV] END .............................eps=0.6, min_samples=5; total time=  16.8s\n",
      "[CV] END ............................eps=0.6, min_samples=15; total time=  17.4s\n",
      "[CV] END .............................eps=0.7, min_samples=5; total time=  17.7s\n",
      "[CV] END ............................eps=0.7, min_samples=15; total time=  17.2s\n",
      "[CV] END .............................eps=0.8, min_samples=7; total time=  18.9s\n",
      "[CV] END ............................eps=0.8, min_samples=15; total time=  12.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DBSCAN(), n_jobs=-1,\n",
       "             param_grid={&#x27;eps&#x27;: [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
       "                         &#x27;min_samples&#x27;: [3, 5, 7, 10, 15]},\n",
       "             scoring=&lt;__main__.SilhouetteScorer object at 0x172fdef70&gt;,\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=DBSCAN(), n_jobs=-1,\n",
       "             param_grid={&#x27;eps&#x27;: [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
       "                         &#x27;min_samples&#x27;: [3, 5, 7, 10, 15]},\n",
       "             scoring=&lt;__main__.SilhouetteScorer object at 0x172fdef70&gt;,\n",
       "             verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: DBSCAN</label><div class=\"sk-toggleable__content fitted\"><pre>DBSCAN(eps=0.7, min_samples=15)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DBSCAN<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.DBSCAN.html\">?<span>Documentation for DBSCAN</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DBSCAN(eps=0.7, min_samples=15)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DBSCAN(), n_jobs=-1,\n",
       "             param_grid={'eps': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
       "                         'min_samples': [3, 5, 7, 10, 15]},\n",
       "             scoring=<__main__.SilhouetteScorer object at 0x172fdef70>,\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "grid_search_dbscan.fit(x_train_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baffb54a-ef49-4e28-8eb4-221ec56ed798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for DBSCAN: {'eps': 0.7, 'min_samples': 15}\n",
      "Best Cross-Validation Score: 0.6248124837875366\n"
     ]
    }
   ],
   "source": [
    "# best parameters and best score\n",
    "best_params_dbscan = grid_search_dbscan.best_params_\n",
    "best_score_dbscan = grid_search_dbscan.best_score_\n",
    "\n",
    "print(f'Best Parameters for DBSCAN: {best_params_dbscan}')\n",
    "print(f'Best Cross-Validation Score: {best_score_dbscan}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1161b917-7df9-4c9d-8045-49dc7fe33270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on validation set\n",
    "dbscan_best_model = grid_search_dbscan.best_estimator_\n",
    "y_val_pred = dbscan_best_model.fit_predict(x_val_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fd02f5f-5739-4dda-8e4a-e597212a1cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Validation Silhouette Score: 0.7250626683235168\n",
      "DBSCAN Validation Accuracy: 0.7364\n",
      "DBSCAN Validation Confusion Matrix:\n",
      "[[    0     0     0     0     0]\n",
      " [  290 18395     0     0     0]\n",
      " [ 1337  4924    15    15    24]\n",
      " [    0     0     0     0     0]\n",
      " [    0     0     0     0     0]]\n",
      "DBSCAN Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.79      0.98      0.88     18685\n",
      "           1       1.00      0.00      0.00      6315\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74     25000\n",
      "   macro avg       0.36      0.20      0.18     25000\n",
      "weighted avg       0.84      0.74      0.66     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate silhouette score\n",
    "silhouette_avg = silhouette_score(x_val_sampled, y_val_pred)\n",
    "\n",
    "print(f'DBSCAN Validation Silhouette Score: {silhouette_avg}')\n",
    "\n",
    "val_accuracy = accuracy_score(y_val_sampled, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val_sampled, y_val_pred)\n",
    "val_classification_report = classification_report(y_val_sampled, y_val_pred, zero_division=0)\n",
    "\n",
    "print(f'DBSCAN Validation Accuracy: {val_accuracy}')\n",
    "print('DBSCAN Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('DBSCAN Validation Classification Report:')\n",
    "print(val_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e459ca8-216e-46d9-96ba-b0a3ab2ea0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Validation Silhouette Score: 0.5844689607620239\n",
      "DBSCAN Test Accuracy: 0.72432\n",
      "DBSCAN Test Confusion Matrix:\n",
      "[[    0     0     0     0     0     0]\n",
      " [  286 18087     0     2     1     1]\n",
      " [ 1490  5072    21    11    15    14]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]]\n",
      "DBSCAN Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.78      0.98      0.87     18377\n",
      "           1       1.00      0.00      0.01      6623\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.30      0.16      0.15     25000\n",
      "weighted avg       0.84      0.72      0.64     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "y_test_pred = dbscan_best_model.fit_predict(x_test_sampled)\n",
    "test_accuracy = accuracy_score(y_test_sampled, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test_sampled, y_test_pred)\n",
    "test_classification_report = classification_report(y_test_sampled, y_test_pred, zero_division=0)\n",
    "\n",
    "# calculate silhouette score\n",
    "silhouette_avg = silhouette_score(x_test_sampled, y_test_pred)\n",
    "\n",
    "print(f'DBSCAN Validation Silhouette Score: {silhouette_avg}')\n",
    "\n",
    "print(f'DBSCAN Test Accuracy: {test_accuracy}')\n",
    "print('DBSCAN Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('DBSCAN Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4c539bf-4cdf-416b-85bb-bef58cda4df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract the cluster labels\n",
    "labels = dbscan_best_model.fit_predict(x_val_sampled)\n",
    "\n",
    "# number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "# plot the clustered data\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = x_val_sampled[class_member_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88aee5a6-fea4-4e99-8470-30a9cc90a9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(x_val_sampled, labels)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "fig.set_size_inches(18, 7)\n",
    "\n",
    "# silhouette coefficient - focus on 0 to 1\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "ax1.set_ylim([0, len(x_val_sampled) + (n_clusters_ + 1) * 10])\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters_):\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[labels == i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = cm.nipy_spectral(float(i) / n_clusters_)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, ith_cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    # compute  new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "# vertical line for average silhouette score of all the values\n",
    "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax1.set_yticks([]) \n",
    "ax1.set_xticks(np.arange(-0.1, 1.1, 0.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd0cd06b-26e9-49d7-bd9f-e8c487b8fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned DBSCAN model saved at: models/dbscan_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# save tuned DBSCAN model\n",
    "dbscan_best_model_path = 'models/dbscan_best_model.pkl'\n",
    "joblib.dump(dbscan_best_model, dbscan_best_model_path)\n",
    "\n",
    "print(f'Tuned DBSCAN model saved at: {dbscan_best_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63768d6-b3b1-4495-b93c-8ca4aa13b1e3",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2386b135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5350203866026181\n",
      "Validation Accuracy: 0.7596279675461051\n",
      "Test Accuracy: 0.7604338223090378\n",
      "\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86    116831\n",
      "           1       0.75      0.08      0.15     39822\n",
      "\n",
      "    accuracy                           0.76    156653\n",
      "   macro avg       0.76      0.54      0.50    156653\n",
      "weighted avg       0.76      0.76      0.68    156653\n",
      "\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86    116832\n",
      "           1       0.77      0.08      0.15     39822\n",
      "\n",
      "    accuracy                           0.76    156654\n",
      "   macro avg       0.76      0.54      0.50    156654\n",
      "weighted avg       0.76      0.76      0.68    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_model = AdaBoostClassifier(base_estimator=model, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model on the PCA-transformed and scaled training data\n",
    "adaboost_model.fit(x_train_scaled_pca, y_train)\n",
    "\n",
    "# Predict on the PCA-transformed and scaled training data\n",
    "y_train_pred = adaboost_model.predict(x_train_scaled_pca)\n",
    "\n",
    "# Predict on the PCA-transformed and scaled validation data\n",
    "y_val_pred = adaboost_model.predict(x_val_scaled_pca)\n",
    "\n",
    "# Predict on the PCA-transformed and scaled test data\n",
    "y_test_pred = adaboost_model.predict(x_test_scaled_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446a6ec",
   "metadata": {},
   "source": [
    "## SVM model with kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcba48a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8429620172358762\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89     11544\n",
      "           1       0.69      0.72      0.71      4121\n",
      "\n",
      "    accuracy                           0.84     15665\n",
      "   macro avg       0.80      0.80      0.80     15665\n",
      "weighted avg       0.84      0.84      0.84     15665\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10243  1301]\n",
      " [ 1159  2962]]\n",
      "Test Accuracy: 0.8472390679859559\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     11665\n",
      "           1       0.69      0.73      0.71      4000\n",
      "\n",
      "    accuracy                           0.85     15665\n",
      "   macro avg       0.80      0.81      0.80     15665\n",
      "weighted avg       0.85      0.85      0.85     15665\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10348  1317]\n",
      " [ 1076  2924]]\n"
     ]
    }
   ],
   "source": [
    "# Sample the data (10% of the data)\n",
    "x_train_sampled, _, y_train_sampled, _ = train_test_split(x_train_scaled_pca, y_train, test_size=0.9, random_state=42)\n",
    "x_val_sampled, _, y_val_sampled, _ = train_test_split(x_val_scaled_pca, y_val, test_size=0.9, random_state=42)\n",
    "x_test_sampled, _, y_test_sampled, _ = train_test_split(x_test_scaled_pca, y_test, test_size=0.9, random_state=42)\n",
    "\n",
    "# Create the SVM model with a kernel trick, for example, the 'rbf' kernel\n",
    "svm_model = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "\n",
    "# Train the model on the sampled data\n",
    "svm_model.fit(x_train_sampled, y_train_sampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = svm_model.predict(x_val_sampled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_sampled, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_sampled, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_sampled, y_val_pred))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = svm_model.predict(x_test_sampled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_sampled, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_sampled, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_sampled, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954fbd8",
   "metadata": {},
   "source": [
    "### Logistic modeling with Lasso / Ridge\n",
    "\n",
    "In looking to refine the Logistic regression model for higher accuracy, the lasso and ridge variation of the model was utilized. First, the data x_train_scaled_pca was fitted to the default Ridge and Lasso models. Five fold cross validation was used to get the average accuracy of each model. The average accuracy for each model is as follows:\n",
    "\n",
    "| Model | Parameters | Dataset | Accuracy |\n",
    "| --- | --- | --- | --- |\n",
    "| Ridge | Default | 5-Fold Validation | 0.73 (average)|\n",
    "|  | Default | Single Validation |  0.82 |\n",
    "|  | Default | Test |  0.83 |\n",
    "|  | Tuned, C = 1 | Validation |   0.82 |\n",
    "|  | Test, C = 1 | Test |  0.83 |\n",
    "| Lasso | Default | 5-Fold Validation |  0.73 (average)|\n",
    "|  | Default | Single Validation |  0.82 |\n",
    "|  | Default | Test |  0.83 |\n",
    "|  | Tuned, C = 1 | Single Validation |  0.82 |\n",
    "|  | Tuned, C = 1 | Test |  0.83 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds\n",
    "n_splits = 5\n",
    "\n",
    "# K-Fold cross-validator\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Ridge Classification with K-Fold CV\n",
    "ridge_model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000, random_state= 42)\n",
    "ridge_accuracy_scores = cross_val_score(ridge_model, x_train_scaled_pca, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f'Ridge Classification Accuracy CV Scores: {ridge_accuracy_scores}')\n",
    "print(f'Ridge Classification Mean Accuracy CV Score: {np.mean(ridge_accuracy_scores)}')\n",
    "\n",
    "# Lasso Classification with K-Fold CV\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='saga', max_iter=1000, random_state= 42)  # 'saga' solver supports L1 regularization\n",
    "lasso_accuracy_scores = cross_val_score(lasso_model, x_train_scaled_pca, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f'Lasso Classification Accuracy CV Scores: {lasso_accuracy_scores}')\n",
    "print(f'Lasso Classification Mean Accuracy CV Score: {np.mean(lasso_accuracy_scores)}')\n",
    "\n",
    "# Training the models on the entire training set and evaluating on the validation set\n",
    "ridge_model.fit(x_train_scaled_pca, y_train)\n",
    "lasso_model.fit(x_train_scaled_pca, y_train)\n",
    "\n",
    "# Evaluate Ridge model on the validation set\n",
    "y_val_pred_ridge = ridge_model.predict(x_val_scaled_pca)\n",
    "val_accuracy_ridge = accuracy_score(y_val, y_val_pred_ridge)\n",
    "val_confusion_matrix_ridge = confusion_matrix(y_val, y_val_pred_ridge)\n",
    "val_classification_report_ridge = classification_report(y_val, y_val_pred_ridge)\n",
    "\n",
    "print('\\nRidge Classification Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix_ridge)\n",
    "print('Ridge Classification Validation Classification Report:')\n",
    "print(val_classification_report_ridge)\n",
    "print(f'Ridge Classification Validation Accuracy: {val_accuracy_ridge}')\n",
    "\n",
    "# Evaluate Ridge model on the test set\n",
    "y_test_pred_ridge = ridge_model.predict(x_test_scaled_pca)\n",
    "test_accuracy_ridge = accuracy_score(y_test, y_test_pred_ridge)\n",
    "test_confusion_matrix_ridge = confusion_matrix(y_test, y_test_pred_ridge)\n",
    "test_classification_report_ridge = classification_report(y_test, y_test_pred_ridge)\n",
    "\n",
    "print('\\nRidge Classification Test Confusion Matrix:')\n",
    "print(test_confusion_matrix_ridge)\n",
    "print('\\nRidge Classification Test Classification Report:')\n",
    "print(test_classification_report_ridge)\n",
    "print(f'Ridge Classification Test Accuracy: {test_accuracy_ridge}')\n",
    "\n",
    "# Evaluate Lasso model on the validation set\n",
    "y_val_pred_lasso = lasso_model.predict(x_val_scaled_pca)\n",
    "val_accuracy_lasso = accuracy_score(y_val, y_val_pred_lasso)\n",
    "val_confusion_matrix_lasso = confusion_matrix(y_val, y_val_pred_lasso)\n",
    "val_classification_report_lasso = classification_report(y_val, y_val_pred_lasso)\n",
    "\n",
    "print('\\nLasso Classification Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix_lasso)\n",
    "print('Lasso Classification Validation Classification Report:')\n",
    "print(val_classification_report_lasso)\n",
    "print(f'Lasso Classification Validation Accuracy: {val_accuracy_lasso}')\n",
    "\n",
    "# Evaluate Lasso model on the test set\n",
    "y_test_pred_lasso = lasso_model.predict(x_test_scaled_pca)\n",
    "val_accuracy_lasso = accuracy_score(y_test, y_test_pred_lasso)\n",
    "val_confusion_matrix_lasso = confusion_matrix(y_test, y_test_pred_lasso)\n",
    "val_classification_report_lasso = classification_report(y_test, y_test_pred_lasso)\n",
    "\n",
    "print('\\nLasso Classification Test Confusion Matrix:')\n",
    "print(val_confusion_matrix_lasso)\n",
    "print('\\nLasso Classification Test Classification Report:')\n",
    "print(val_classification_report_lasso)\n",
    "print(f'Lasso Classification Test Accuracy: {val_accuracy_lasso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a4a0b",
   "metadata": {},
   "source": [
    "##### Hyper parameter tuning for the Ridge and Lasso Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87933d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Ridge and Lasso\n",
    "ridge_param_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # inverse of regularization strength\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [1000],\n",
    "    'random_state': [42]  # set seed\n",
    "}\n",
    "\n",
    "lasso_param_grid = {\n",
    "    'penalty': ['l1'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # inverse of regularization strength\n",
    "    'solver': ['saga'],\n",
    "    'max_iter': [1000],\n",
    "    'random_state': [42]  # Set the seed\n",
    "}\n",
    "\n",
    "# Create GridSearchCV objects\n",
    "ridge_grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),  # set seed for reproducibility\n",
    "    ridge_param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',  \n",
    "    n_jobs=-1  # use all available cores\n",
    ")\n",
    "\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),  # set seed for reproducibility\n",
    "    lasso_param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',  \n",
    "    n_jobs=-1  # use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV objects\n",
    "ridge_grid_search.fit(x_train_scaled_pca, y_train)\n",
    "lasso_grid_search.fit(x_train_scaled_pca, y_train)\n",
    "\n",
    "# Get the best parameters and best scores\n",
    "print(f'\\nBest Ridge parameters: {ridge_grid_search.best_params_}')\n",
    "print(f'Best Ridge CV accuracy: {ridge_grid_search.best_score_}')\n",
    "\n",
    "print(f'\\nBest Lasso parameters: {lasso_grid_search.best_params_}')\n",
    "print(f'Best Lasso CV accuracy: {lasso_grid_search.best_score_}')\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_ridge_model = ridge_grid_search.best_estimator_\n",
    "best_lasso_model = lasso_grid_search.best_estimator_\n",
    "\n",
    "# Validation set evaluation for Ridge\n",
    "y_val_pred_ridge = best_ridge_model.predict(x_val_scaled_pca)\n",
    "val_accuracy_ridge = accuracy_score(y_val, y_val_pred_ridge)\n",
    "val_confusion_matrix_ridge = confusion_matrix(y_val, y_val_pred_ridge)\n",
    "val_classification_report_ridge = classification_report(y_val, y_val_pred_ridge)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nBest Ridge Classification Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix_ridge)\n",
    "print('Best Ridge Classification Validation Classification Report:')\n",
    "print(val_classification_report_ridge)\n",
    "print(f'Best Ridge Classification Validation Accuracy: {val_accuracy_ridge}')\n",
    "\n",
    "# Test set evaluation for Ridge\n",
    "y_test_pred_ridge = best_ridge_model.predict(x_test_scaled_pca)\n",
    "test_accuracy_ridge = accuracy_score(y_test, y_test_pred_ridge)\n",
    "test_confusion_matrix_ridge = confusion_matrix(y_test, y_test_pred_ridge)\n",
    "test_classification_report_ridge = classification_report(y_test, y_test_pred_ridge)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nBest Ridge Classification Test Confusion Matrix:')\n",
    "print(test_confusion_matrix_ridge)\n",
    "print('Best Ridge Classification Test Classification Report:')\n",
    "print(test_classification_report_ridge)\n",
    "print(f'Best Ridge Classification Test Accuracy: {test_accuracy_ridge}')\n",
    "\n",
    "# Validation set evaluation for Lasso\n",
    "y_val_pred_lasso = best_lasso_model.predict(x_val_scaled_pca)\n",
    "val_accuracy_lasso = accuracy_score(y_val, y_val_pred_lasso)\n",
    "val_confusion_matrix_lasso = confusion_matrix(y_val, y_val_pred_lasso)\n",
    "val_classification_report_lasso = classification_report(y_val, y_val_pred_lasso)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nBest Lasso Classification Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix_lasso)\n",
    "print('Best Lasso Classification Validation Classification Report:')\n",
    "print(val_classification_report_lasso)\n",
    "print(f'Best Lasso Classification Validation Accuracy: {val_accuracy_lasso}')\n",
    "\n",
    "# Test set evaluation for Lasso\n",
    "y_test_pred_lasso = best_lasso_model.predict(x_test_scaled_pca)\n",
    "test_accuracy_lasso = accuracy_score(y_test, y_test_pred_lasso)\n",
    "test_confusion_matrix_lasso = confusion_matrix(y_test, y_test_pred_lasso)\n",
    "test_classification_report_lasso = classification_report(y_test, y_test_pred_lasso)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nBest Lasso Classification Test Confusion Matrix:')\n",
    "print(test_confusion_matrix_lasso)\n",
    "print('Best Lasso Classification Test Classification Report:')\n",
    "print(test_classification_report_lasso)\n",
    "print(f'Best Lasso Classification Test Accuracy: {test_accuracy_lasso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73298e1",
   "metadata": {},
   "source": [
    "The best hyperparameters for the Ridge and Lasso Models were the default. The test accuracy was 83% for both untuned and tuned Ridge and Lasso models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138bf49c",
   "metadata": {},
   "source": [
    "### K means clustering \n",
    "\n",
    "Let's try out a simple unsupervised method - K means clustering. This method will be used to group data points together into clusters based on their similarity. It can help identify natural groupings of the data along with feature relationships. After running the elbow and silhouette methods to determine the number of clusters, they both agreed on clusters of 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store clusters\n",
    "cluster_nums = []\n",
    "\n",
    "# Range of cluster numbers\n",
    "range_n_clusters = range(1, 11)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(x_train_scaled_pca)\n",
    "    cluster_nums.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the elbow curve\n",
    "plt.plot(range_n_clusters, cluster_nums, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to tune the number of clusters used with the silhouette method and early stopping\n",
    "# using only a sample of the data as 1 million is not doable with current computing power\n",
    "def kmeans_with_early_stopping(data, max_clusters=6, patience=3, subset_size=0.1):\n",
    "    # sample a subset of the data\n",
    "    data_subset = data.sample(frac=subset_size, random_state=42)\n",
    "    \n",
    "    best_score = -1\n",
    "    best_n_clusters = 0\n",
    "    best_labels = None\n",
    "    no_improvement_count = 0\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(data_subset)\n",
    "        silhouette_avg = silhouette_score(data_subset, cluster_labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        \n",
    "        if silhouette_avg > best_score:\n",
    "            best_score = silhouette_avg\n",
    "            best_n_clusters = n_clusters\n",
    "            best_labels = cluster_labels\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "        \n",
    "        if no_improvement_count >= patience:\n",
    "            print(f\"Early stopping at {n_clusters} clusters with best silhouette score: {best_score}\")\n",
    "            break\n",
    "    \n",
    "    # Fit the best model on the full data\n",
    "    final_kmeans = KMeans(n_clusters=best_n_clusters, random_state=42)\n",
    "    final_labels = final_kmeans.fit_predict(data)\n",
    "    \n",
    "    return best_n_clusters, final_labels, silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the user defined function\n",
    "best_n_clusters, best_labels, silhouette_scores = kmeans_with_early_stopping(x_train_scaled_pca, subset_size=.05)\n",
    "\n",
    "# plotting the silhouette scores\n",
    "plt.plot(range(2, 2 + len(silhouette_scores)), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis with Early Stopping on Subset')\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal number of clusters: {best_n_clusters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16b765",
   "metadata": {},
   "source": [
    "Since we have 3 principal components, a 3d graph was rendered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fit KMeans and Get Cluster Labels\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(x_train_scaled_pca)\n",
    "\n",
    "# Create a DataFrame with PCA components and cluster labels\n",
    "df_clusters = pd.DataFrame(x_train_scaled_pca, columns=[f'PC{i}' for i in range(1, x_train_scaled_pca.shape[1] + 1)])\n",
    "df_clusters['Cluster'] = cluster_labels\n",
    "\n",
    "# Step 2: Examine Cluster Centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "centroid_df = pd.DataFrame(centroids, columns=[f'PC{i}' for i in range(1, x_train_scaled_pca.shape[1] + 1)])\n",
    "print(\"Cluster Centroids:\")\n",
    "print(centroid_df)\n",
    "\n",
    "# Step 3: Analyze Feature Contributions\n",
    "feature_means = df_clusters.groupby('Cluster').mean()\n",
    "print(\"\\nFeature Means by Cluster:\")\n",
    "print(feature_means)\n",
    "\n",
    "# Step 4: Visualize Clusters in 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot each cluster in a different color\n",
    "colors = sns.color_palette('viridis', 2)\n",
    "for cluster in range(2):\n",
    "    cluster_data = df_clusters[df_clusters['Cluster'] == cluster]\n",
    "    ax.scatter(cluster_data['PC1'], cluster_data['PC2'], cluster_data['PC3'], \n",
    "               label=f'Cluster {cluster}', color=colors[cluster], s=50, alpha=0.6, edgecolors='w')\n",
    "\n",
    "# Plot centroids\n",
    "ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], s=300, c='red', label='Centroids', marker='X')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('3D Clusters Visualization')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d54210",
   "metadata": {},
   "source": [
    "#### *PCA Results for clustering explained*\n",
    "\n",
    "Cluster 0 (light blue) and Cluster 1 (light green) are the two clusters identified by the KMeans algorithm and each point is an observation plotted against the three principal components. The centroids (red X markers) represent the mean position of all points within each cluster in the 3D space defined by the principal components. The centroids are the center of each cluster. For example, Cluster 0 has its centroid around (-1.041730, 0.098865, 0.006195) while Cluster 1 has its centroid around (1036.332647, -98.353172, -6.162892). These values indicate where the central points of the clusters are located in the reduced PCA space.\n",
    "\n",
    "In Cluster 0, the average value for PC1 is -1.041730, while for Cluster 1, it is 1036.332647. In Cluster 0, the points in this cluster are grouped around the centroid (-1.041730, 0.098865, 0.006195). This cluster represents observations that share similar characteristics in the PCA-transformed feature space, typically closer to the origin.\n",
    "\n",
    "In Cluster 1, the points in this cluster are grouped around the centroid (1036.332647, -98.353172, -6.162892). This cluster represents observations that are significantly different from those in Cluster 0, as shown by the large difference in the centroid values, especially along PC1 (-1.041730 and 1036.332647).\n",
    "\n",
    "Let's see how much of each feature influenced the principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f033b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaled = PCA(n_components=3)\n",
    "new_X_train_scaled_pca = pca_scaled.fit_transform(x_train_scaled)\n",
    "components = pca_scaled.components_\n",
    "evr = pca_scaled.explained_variance_ratio_\n",
    "\n",
    "loadings_scaled = pd.DataFrame(components.T, columns=[f'PC{i+1}' for i in range(components.shape[0])], index=[x_train_scaled.columns])\n",
    "# Sort each column in ascending order\n",
    "sorted_loadings_scaled = loadings_scaled.apply(lambda x: x.sort_values())\n",
    "\n",
    "print(\"\\nSorted Loadings Scaled:\")\n",
    "print(sorted_loadings_scaled)\n",
    "\n",
    "# Print sorted values for each PC individually\n",
    "for i in range(components.shape[0]):\n",
    "    sorted_pc = loadings_scaled[f'PC{i+1}'].sort_values(ascending=True)\n",
    "    print(f\"\\nSorted Loadings for PC{i+1}:\")\n",
    "    print(sorted_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and select top 20 features for each component, can change if needed\n",
    "top_features_per_pc = {}\n",
    "num_top_features = 20\n",
    "\n",
    "for pc in loadings_scaled.columns:\n",
    "    top_features = loadings_scaled[pc].abs().sort_values(ascending=False).head(num_top_features).index\n",
    "    top_features_per_pc[pc] = top_features\n",
    "\n",
    "# Get unique top features\n",
    "unique_top_features = list(set([feature for features in top_features_per_pc.values() for feature in features]))\n",
    "\n",
    "# Filter DataFrame to include only top features\n",
    "loadings_scaled_top = loadings_scaled.loc[unique_top_features]\n",
    "\n",
    "# Perform hierarchical clustering on top features\n",
    "Z = linkage(loadings_scaled_top, 'ward')\n",
    "\n",
    "# Plot clustered heatmap\n",
    "sns.clustermap(loadings_scaled_top, annot=True, cmap='coolwarm', linewidths=0.5, figsize=(20, 15), row_cluster=True, col_cluster=False)\n",
    "plt.title('Heatmap of Top Feature Contributions to Principal Components with Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137794ee",
   "metadata": {},
   "source": [
    "According to this visualization, within the top 20 features, the 6 that stand out are total payment, number of users, number of providers, average number of providers per county, number of fee for service benficiaries and average number of users per provider."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
