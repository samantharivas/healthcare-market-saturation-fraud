{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c988869a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f34cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # supress warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3cd24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\jessh\\Documents\\MS_Applied_Data_Science\\ADS599 Capstone Project\\Project\n"
     ]
    }
   ],
   "source": [
    "# Check current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd07646",
   "metadata": {},
   "source": [
    "#### Read in data from the preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf93427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "# all the training/validation/test dataframes\n",
    "x_train = pd.read_csv('data/x_train.csv') \n",
    "x_train_scaled = pd.read_csv('data/x_train_scaled.csv')\n",
    "x_train_pca = pd.read_csv('data/x_train_pca.csv')\n",
    "x_train_scaled_pca = pd.read_csv('data/x_train_scaled_pca.csv')\n",
    "\n",
    "x_val = pd.read_csv('data/x_val.csv') \n",
    "x_val_scaled = pd.read_csv('data/x_val_scaled.csv')\n",
    "x_val_pca = pd.read_csv('data/x_val_pca.csv')\n",
    "x_val_scaled_pca = pd.read_csv('data/x_val_scaled_pca.csv')\n",
    "\n",
    "x_test = pd.read_csv('data/x_test.csv')\n",
    "x_test_scaled = pd.read_csv('data/x_test_scaled.csv')\n",
    "x_test_pca = pd.read_csv('data/x_test_pca.csv')\n",
    "x_test_scaled_pca = pd.read_csv('data/x_test_scaled_pca.csv')\n",
    "\n",
    "\n",
    "# all the labels\n",
    "y_train = np.ravel(pd.read_csv('data/y_train.csv'))\n",
    "y_val = np.ravel(pd.read_csv('data/y_val.csv'))\n",
    "y_test = np.ravel(pd.read_csv('data/y_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d9c92",
   "metadata": {},
   "source": [
    "#### Yeo Johnson transformation of data\n",
    "\n",
    "We wanted to add in additional dataframes to see if there was a difference in modeling performance. This Yeo-Johnson transformation was one of them, another would be to do transformation + scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd538566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed data\n",
    "# create copy of df \n",
    "x_train_transformed = x_train.copy()\n",
    "x_val_transformed = x_val.copy()\n",
    "x_test_transformed = x_test.copy()\n",
    "\n",
    "# get numeric columns\n",
    "numeric_columns = x_train_transformed.select_dtypes(include=['float']).columns\n",
    "\n",
    "def yeo_johnson_transform(column):\n",
    "    # Create an instance of PowerTransformer with Yeo-Johnson method\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    # Reshape column for PowerTransformer which expects 2D input\n",
    "    column_reshaped = column.values.reshape(-1, 1)\n",
    "    \n",
    "    # Fit and transform the column\n",
    "    transformed_col = pt.fit_transform(column_reshaped)\n",
    "    \n",
    "    # Flatten the result to match original column shape\n",
    "    return transformed_col.flatten()\n",
    "\n",
    "# Apply Box-Cox transformation to each numeric column\n",
    "for col in numeric_columns:\n",
    "    x_train_transformed[col] = yeo_johnson_transform(x_train_transformed[col])\n",
    "    x_val_transformed[col] = yeo_johnson_transform(x_val_transformed[col])\n",
    "    x_test_transformed[col] = yeo_johnson_transform(x_test_transformed[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e87ee19",
   "metadata": {},
   "source": [
    "#### Log transformed + scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87097630",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trans_scaled = x_train_transformed.copy()\n",
    "x_val_trans_scaled = x_val_transformed.copy()\n",
    "x_test_trans_scaled = x_test_transformed.copy()\n",
    "\n",
    "scaler = RobustScaler()\n",
    "x_train_trans_scaled[numeric_columns] = scaler.fit_transform(x_train_trans_scaled[numeric_columns])\n",
    "x_val_trans_scaled[numeric_columns] = scaler.transform(x_val_trans_scaled[numeric_columns])\n",
    "x_test_trans_scaled[numeric_columns] = scaler.transform(x_test_trans_scaled[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced5f2b",
   "metadata": {},
   "source": [
    "## Baseline Model Selection - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461c82d",
   "metadata": {},
   "source": [
    "We'll first start by deciding on a baseline model for comparison against other models. The confusion matrix will be used to determine which dataframe will be ingested for each machine learning model. We currently have the following dataframes/data to feed into the logistic regression model:\n",
    "\n",
    "* The preprocessed data - x_train\n",
    "* The transformed data - x_train_tranformed\n",
    "* The scaled data - x_train_scaled\n",
    "* The transformed + scaled data - x_train_trans_scaled\n",
    "* The pca transformed data - x_train_pca\n",
    "* The scaled data + pca - x_train_scaled_pca\n",
    "\n",
    "Based on the results of the baseline regression model, we can choose a dataframe to carry through the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2985f35",
   "metadata": {},
   "source": [
    "#### Create and train Logistic Regression Model for unscaled data\n",
    "\n",
    "This is the first model with the data that has been preprocessed but not scaled nor transformed for normality. The accuracy was terrible, the precision and F-score were non existant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a08832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jessh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jessh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.25420515406663136\n",
      "Validation Confusion Matrix:\n",
      "[[     0 116831]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    116831\n",
      "           1       0.25      1.00      0.41     39822\n",
      "\n",
      "    accuracy                           0.25    156653\n",
      "   macro avg       0.13      0.50      0.20    156653\n",
      "weighted avg       0.06      0.25      0.10    156653\n",
      "\n",
      "Test Accuracy: 0.25420353134934315\n",
      "Test Confusion Matrix:\n",
      "[[     0 116832]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    116832\n",
      "           1       0.25      1.00      0.41     39822\n",
      "\n",
      "    accuracy                           0.25    156654\n",
      "   macro avg       0.13      0.50      0.20    156654\n",
      "weighted avg       0.06      0.25      0.10    156654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jessh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jessh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747ae41",
   "metadata": {},
   "source": [
    "#### Create and train Logistic Regression Model for the scaled data\n",
    "\n",
    "This is the first model with the data that has been preprocessed and scaled, but not transformed for normality. The accuracy was 100%, leading us to believe that the model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "257255a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n",
      "Validation Confusion Matrix:\n",
      "[[116831      0]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116831\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156653\n",
      "   macro avg       1.00      1.00      1.00    156653\n",
      "weighted avg       1.00      1.00      1.00    156653\n",
      "\n",
      "Test Accuracy: 1.0\n",
      "Test Confusion Matrix:\n",
      "[[116832      0]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116832\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156654\n",
      "   macro avg       1.00      1.00      1.00    156654\n",
      "weighted avg       1.00      1.00      1.00    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_scaled)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f2c69",
   "metadata": {},
   "source": [
    "#### Create and train Logistic Regression Model for yeo-johnson transformed data\n",
    "\n",
    "This is the first model with the data that has been preprocessed and transformed, but not scaled. The accuracy was 100%, leading us to believe that the model is also overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd8ef62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n",
      "Validation Confusion Matrix:\n",
      "[[116831      0]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116831\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156653\n",
      "   macro avg       1.00      1.00      1.00    156653\n",
      "weighted avg       1.00      1.00      1.00    156653\n",
      "\n",
      "Test Accuracy: 1.0\n",
      "Test Confusion Matrix:\n",
      "[[116832      0]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116832\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156654\n",
      "   macro avg       1.00      1.00      1.00    156654\n",
      "weighted avg       1.00      1.00      1.00    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_transformed, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_transformed)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_transformed)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce41b5",
   "metadata": {},
   "source": [
    "#### Create and train Logistic Regression Model for yeo-johnson transformed and scaled data\n",
    "\n",
    "This is the first model with the data that has been preprocessed, scaled, and transformed for normality. The accuracy was 100%, leading us to believe that the model is also overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a8b7521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n",
      "Validation Confusion Matrix:\n",
      "[[116831      0]\n",
      " [     0  39822]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116831\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156653\n",
      "   macro avg       1.00      1.00      1.00    156653\n",
      "weighted avg       1.00      1.00      1.00    156653\n",
      "\n",
      "Test Accuracy: 1.0\n",
      "Test Confusion Matrix:\n",
      "[[116832      0]\n",
      " [     0  39822]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    116832\n",
      "           1       1.00      1.00      1.00     39822\n",
      "\n",
      "    accuracy                           1.00    156654\n",
      "   macro avg       1.00      1.00      1.00    156654\n",
      "weighted avg       1.00      1.00      1.00    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_trans_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_trans_scaled)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_trans_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52b7ac",
   "metadata": {},
   "source": [
    "#### Create and train Logistic Regression Model for the PCA transformed data (orig)\n",
    "\n",
    "This is the fifth model with the data that has been preprocessed, but not scaled nor transformed for normality. The accuracy was about 81%, which is the best model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ebc563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8094706133939343\n",
      "Validation Confusion Matrix:\n",
      "[[114853   1978]\n",
      " [ 27869  11953]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.89    116831\n",
      "           1       0.86      0.30      0.44     39822\n",
      "\n",
      "    accuracy                           0.81    156653\n",
      "   macro avg       0.83      0.64      0.66    156653\n",
      "weighted avg       0.82      0.81      0.77    156653\n",
      "\n",
      "Test Accuracy: 0.8097080189462127\n",
      "Test Confusion Matrix:\n",
      "[[114859   1973]\n",
      " [ 27837  11985]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.89    116832\n",
      "           1       0.86      0.30      0.45     39822\n",
      "\n",
      "    accuracy                           0.81    156654\n",
      "   macro avg       0.83      0.64      0.67    156654\n",
      "weighted avg       0.82      0.81      0.77    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_pca, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_pca)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_pca)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0b7d7",
   "metadata": {},
   "source": [
    "# Create and train Logistic Regression Model for the PCA transformed data (scaled)\n",
    "\n",
    "This is the sixth model with the data that has been preprocessed and scaled, but not transformed for normality. The accuracy was about 82%, which is the best model so far beating the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0cfd633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8236739800706019\n",
      "Validation Confusion Matrix:\n",
      "[[107864   8967]\n",
      " [ 18655  21167]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89    116831\n",
      "           1       0.70      0.53      0.61     39822\n",
      "\n",
      "    accuracy                           0.82    156653\n",
      "   macro avg       0.78      0.73      0.75    156653\n",
      "weighted avg       0.81      0.82      0.81    156653\n",
      "\n",
      "Test Accuracy: 0.82516245994357\n",
      "Test Confusion Matrix:\n",
      "[[108066   8766]\n",
      " [ 18623  21199]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89    116832\n",
      "           1       0.71      0.53      0.61     39822\n",
      "\n",
      "    accuracy                           0.83    156654\n",
      "   macro avg       0.78      0.73      0.75    156654\n",
      "weighted avg       0.82      0.83      0.82    156654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logreg model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_scaled_pca, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = model.predict(x_val_scaled_pca)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "val_classification_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_confusion_matrix)\n",
    "print('Validation Classification Report:')\n",
    "print(val_classification_report)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(x_test_scaled_pca)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "test_classification_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print('Test Confusion Matrix:')\n",
    "print(test_confusion_matrix)\n",
    "print('Test Classification Report:')\n",
    "print(test_classification_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
